---
title: 2.内存管理
date: 2021-04-06 19:46:04
tags: 五、操作系统
categories: 五、操作系统
---

# 虚拟内存空间

为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情

### 内存分段

在虚拟内存空间中，我们将栈、堆等分为不同的段，分别映射到物理内存，通过段表保存虚拟内存到物理内存的映射，寻址时根据虚拟内存地址（段起始地址和段内偏移量），即可找到对应的物理地址

![](https://icefirecgrbza.github.io/img/os/memory_segment.jpg)

![](https://icefirecgrbza.github.io/img/os/memory_segment_map.jpg)

分段机制存在一些问题，会导致内存碎片，小块的内存碎片上，无法分配连续内存给进程，导致浪费

### 内存分页

Linux主要使用分页的机制。相对于分段，页的粒度更小，一般一个页只有4KB大小，一个进程的虚拟空间会有很多个页，这些页分别映射到物理内存的页上，根据页起始地址和页偏移量进行寻址，这有效的避免了内存分段带来的碎片问题，而且可以将不常用的页替换出到硬盘，要使用时再换入

![](https://icefirecgrbza.github.io/img/os/memory_page.jpg)

![](https://icefirecgrbza.github.io/img/os/memory_page_map.jpg)

对于一个32位的系统，虚拟内存空间最多能表示2^32个地址，也就是4GB。一个页4KB，那么就会有1M个页，每个页表项使用4个字节存储（32位用于表示物理地址），那一个进程就需要4MB的内存用于保存页表，100个进程就是400MB，这对内核来说实在是太大了

因此，有了多级页表的机制。我们想象一下，如果我们对4MB的页表再进行分页，每1K个页表归总为一个页目录项，一共1K个页目录项，每个页目录项用4个字节存储，那么只需要4KB就可以表示4GB的虚拟内存空间。当进程使用了4GB的内存时，页表加页表目录项共使用4MB+4KB的内存。但如果使用的内存远小于4GB，那么4MB的页表其实只需要加载一小部分

![](https://icefirecgrbza.github.io/img/os/memory_page_twice.jpg)

对于64位的系统，两级页表肯定是不够的，Linux中使用了4级的页表

![](https://icefirecgrbza.github.io/img/os/memory_page_multi.jpg)

# 内存布局

进程的地址空间被分为用户态和内核态两个部分。用户态内存被分为栈、堆、mmap内存映射、数据、代码等多个部分部分。而内核态内存映射到的物理内存都是相同的，内核态内存分为代码、数据、内核栈、内核数据结构和内核动态分配的内存等

![](https://icefirecgrbza.github.io/img/os/memory_user_kernel.jpg)

![](https://icefirecgrbza.github.io/img/os/memory_user.jpg)

![](https://icefirecgrbza.github.io/img/os/memory_kernel.jpg)

# 内存分配

内存并不是连续的，首先分为节点和区域，区域下再是分页；这一块和计算机硬件相关我们不细讲，大概了解即可

内存分配主要分为两种

+ 通过伙伴系统直接分配页，一般用于大内存的分配；这部分算法比较巧妙，内核维度了n个链表，分别表示2^n个连续页的起始地址，分配时，优先分配相近大小的连续页，若没有，则取更大的连续页，将其拆分为较小的连续页后再分配。举个例子，内核需要分配256个页，但256个页的链表已经空了，就找到512个页的链表，取到连续内存后，将其分为2个256的连续页，插入到256个页的链表中，再进行分配
+ 通过Slub Allocator分配小对象。Slub Allocator会先通过伙伴系统分配大内存，然后通过对象池的方式，分配小对象

当内存紧张的时候，内核线程kswapd通过lru算法，将最不活跃的匿名页换出到文件系统，若是文件映射类型的页，kswapd会将脏页写回到文件（这就是虚拟内存，运用了局部性原理）

![](https://icefirecgrbza.github.io/img/os/memory_allocate.jpeg)

# 内存寻址

多级页表解决了内存寻址和页表存储的问题。页表实际上存储在 CPU 的内存管理单元 （MMU），为了更快速地进行内存寻址，CPU中有TLB的硬件单元，专门用于存放最长使用的页表项

当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行

![](https://icefirecgrbza.github.io/img/os/memory_mmu.png)

# 关于mmap

一般read、write文件读写需要4次用户态和内核态的上下文切换和4次内存拷贝

1. 用户进程通过read()方法向操作系统发起调用，此时上下文从用户态转向内核态
2. DMA控制器把数据从硬盘中拷贝到读缓冲区
3. CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态转为用户态，read()返回
4. 用户进程通过write()方法发起调用，上下文从用户态转为内核态
5. CPU将应用缓冲区中数据拷贝到socket缓冲区
6. DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回

![](https://icefirecgrbza.github.io/img/os/read_write.jpg)

mmap将文件映射到内存，DMA控制器将数据拷贝到内存后，可直接映射到内核态，不需要拷贝

![](https://icefirecgrbza.github.io/img/os/mmap.jpg)

```
#include <sys/mman.h> /* for mmap and munmap */
#include <sys/types.h> /* for open */
#include <sys/stat.h> /* for open */
#include <fcntl.h>     /* for open */
#include <unistd.h>    /* for lseek and write */
#include <stdio.h>
 
int main(int argc, char **argv)
{
  int fd;
  char *mapped_mem, * p;
  int flength = 1024;
  void * start_addr = 0;
 
  fd = open(argv[1], O_RDWR | O_CREAT, S_IRUSR | S_IWUSR);
  flength = lseek(fd, 1, SEEK_END);
  write(fd, "\0", 1); /* 在文件最后添加一个空字符，以便下面printf正常工作 */
  lseek(fd, 0, SEEK_SET);
  mapped_mem = mmap(start_addr, flength, PROT_READ,        //允许读
    MAP_PRIVATE,       //不允许其它进程访问此内存区域
      fd, 0);
  
  /* 使用映射区域. */
  printf("%s\n", mapped_mem); /* 为了保证这里工作正常，参数传递的文件名最好是一个文本文件 */
  close(fd);
  munmap(mapped_mem, flength);
  return 0;
}
```