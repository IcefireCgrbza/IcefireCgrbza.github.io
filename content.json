{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"1. 十大排序算法","text":"排序算法总结在讲排序算法之前，我们先通过给排序算法做个分类，并总结他们的时间复杂度和空间复杂度。 为了简化测试，我我定义了一个抽象类，使用了一个策略模式，接下来的十个排序算法都会继承这个抽象类 12345678910public abstract class Sort { public abstract void sort(int[] arr); protected void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; }} 以下所有排序算法的源码，都可以到我的github上查看：查看源码 在这篇文章中，我们只会讲一些简单、非常用的排序算法，比较重要的冒泡排序、快速排序、归并排序、堆排序我们在后面的文章中再详细讲 选择排序选择排序是最简单的排序算法，它的思想是逐步选出数组的极值，并将它交换到数组的前面，从而打到排序的目的；我们直接看代码 123456789101112131415public class SelectSort extends Sort { @Override public void sort(int[] arr) { for (int i = 0; i &lt; arr.length; i++) { int minIdx = i; for (int j = i + 1; j &lt; arr.length; j++) { if (arr[j] &lt; arr[minIdx]) { minIdx = j; } } swap(arr, i, minIdx); } }} 插入排序插入排序也是简单的排序算法，它的思想是将数值插入到已经有序的数组中；插入排序的时间复杂度受数组元素排列影响，在数组本身有序的情况下，复杂度能到O(n) 1234567891011121314151617public class InsertSort extends Sort { @Override public void sort(int[] arr) { for (int i = 0; i &lt; arr.length; i++) { int tmp = arr[i]; for (int j = i - 1;; j--) { if (j &lt; 0 || arr[j] &lt; tmp) { arr[j + 1] = tmp; break; } else { arr[j + 1] = arr[j]; } } } }} 希尔排序希尔排序是插入排序的改进版，会优先比较相邻较远的元素，加快交换速度；最终退化到插入排序时，整个数组已经相对有序，因此复杂度较低 12345678910111213141516171819public class ShellSort extends Sort { @Override public void sort(int[] arr) { for (int gap = arr.length / 2; gap &gt; 0; gap /= 2) { for (int i = 0; i &lt; arr.length; i++) { int tmp = arr[i]; for (int j = i - gap;; j -= gap) { if (j &lt; 0 || arr[j] &lt; tmp) { arr[j + gap] = tmp; break; } else { arr[j + gap] = arr[j]; } } } } }} 计数排序计数排序仅用于数值在一定范围的数组的排序，它的原理是为范围内每个可能出现的数创建一个槽，用于对每个出现的数值进行计数，最后按次数进行输出 1234567891011121314151617181920212223242526272829303132333435public class CountSort extends Sort { @Override public void sort(int[] arr) { if (arr.length &lt; 1) { return; } int min = arr[0], max = arr[0]; for (int a : arr) { min = min &gt; a ? a : min; max = max &lt; a ? a : max; } //计数 int countLen = max - min + 1; int[] count = new int[countLen]; for (int a : arr) { count[a - min]++; } //acc数组的第i位表示i这个数在sorted中的最后位置，目的是使arr中相同数值具有区分度（不需要区分可省略该步骤） int[] acc = new int[countLen]; for (int i = 0; i &lt; countLen; i++) { acc[i] = i == 0 ? count[i] : (acc[i - 1] + count[i]); } int[] sorted = new int[arr.length]; for (int i = arr.length - 1; i &gt;= 0; i--) { sorted[--acc[arr[i] - min]] = arr[i]; } System.arraycopy(sorted, 0, arr, 0, arr.length); }} 桶排序桶排序将数组切分为n个桶，每个桶负责一定范围的数，分别对每个桶进行排序，最后按桶进行输出 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class BucketSort extends Sort { @Override public void sort(int[] arr) { if (arr.length &lt; 1) { return; } int min = arr[0], max = arr[0]; for (int a : arr) { min = min &gt; a ? a : min; max = max &lt; a ? a : max; } int bucketCount = 5; List&lt;List&lt;Integer&gt;&gt; buckets = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketCount; i++) { buckets.add(new LinkedList&lt;&gt;()); } for (int a : arr) { buckets.get((a - min) / (max - min) * (bucketCount - 1)).add(a); } int[] sorted = new int[arr.length]; int start = 0; for (int i = 0; i &lt; bucketCount; i++) { List&lt;Integer&gt; bucket = buckets.get(i); if (bucket.size() &gt; 0) { Collections.sort(bucket); for (int j = 0; j &lt; bucket.size(); j++) { sorted[start++] = bucket.get(j); } } } System.arraycopy(sorted, 0, arr, 0, arr.length); }} 基数排序基数排序的思想是，低位先排序，高位再排序 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public class RadixSort extends Sort { @Override public void sort(int[] arr) { if (arr.length &lt; 1) { return; } int max = arr[0]; for (int a : arr) { max = max &lt; a ? a : max; } int mod = 10; int dev = 1; do { List&lt;List&lt;Integer&gt;&gt; acc = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { acc.add(new LinkedList&lt;&gt;()); } for (int a : arr) { acc.get((a % mod) / dev).add(a); } int[] sorted = new int[arr.length]; int idx = 0; for (int i = 0; i &lt; 10; i++) { List&lt;Integer&gt; ac = acc.get(i); for (int j = 0; j &lt; ac.size(); j++) { sorted[idx++] = ac.get(j); } } System.arraycopy(sorted, 0, arr, 0, arr.length); mod *= 10; dev *= 10; } while (max &gt; mod); }} 总结上文我们已经讲了6种排序算法，最常见的冒泡排序、快速排序、归并排序、堆排序我们将放到后面四篇文章中分别讲解","link":"/2021/03/07/algo/1.sort/"},{"title":"10. 红黑树","text":"算法简介红黑树也是一种平衡二叉树，为了确保平衡，他有以下特性： 每个节点要么是红色要么是黑色 根节点一定是黑色 叶子节点NULL一定是黑色 红节点的两个子节点一定是黑色 任一结点到它的每个叶子结点的路径都包含数量相同的黑结点 红黑树并不是一种完美平衡的二叉树，可称之为黑平衡，他的树深度不大于黑深度的两倍，最大深度不大于最小深度的两倍（树深度一定大于黑深度，要增加树深度，只能增加红节点，但是红节点的儿子节点一定是黑色，因此红节点不能连续存在，最多只能没相隔一个黑节点增加一个红节点，因此树深度必定不会大于黑深度的两倍） 节点插入插入节点为红色，插入流程与二叉树一致，主要在于插入后，若红黑树失衡，不满足红黑树定义，则必须通过旋转和变色让红黑树重新达到平衡，下面梳理了插入的情况 红黑树为空树 插入节点已存在 插入父节点为黑节点 插入父节点为红节点（由红黑树特性可知，插入节点必有祖父节点，且必为黑色） 叔叔节点为红色 叔叔节点为黑色或NULL 插入节点类型为LL 插入节点类型为LR 插入节点类型为RR 插入节点类型为RL 其中1 2 3这三种情况都不会导致红黑树失衡，情况4会导致红黑树失衡，我们具体看看情况4 4.1情况下，父节点和叔叔节点变为黑色，祖父节点变为红色，那么祖父节点即可重新达到平衡，之后将祖父节点视为插入节点，向上递归 4.2情况下，祖父节点、父节点、插入节点方向上，有两个红节点、一个黑节点，而祖父节点、叔叔节点方向则是两个黑节点，因此可以通过左旋、右旋、变色等方式，将一个红节点移到叔叔节点的方向，从而避免红节点连续存在 节点删除我们先回忆一下二叉树的删除，二叉树的删除分为以下三种情况： 删除节点无叶子节点：直接删除即可 删除节点只有左子节点或右子节点：删除后将子树嫁接到当前位置 删除节点左右子节点均存在：和后继节点替换，然后删除替换节点 这三种情况的存在，让红黑树的删除变得非常复杂，因为我们还需要考虑红黑树的平衡。但我们发现，情况1的处理相对简单，只需要考虑删除节点是红或是黑，并做对应处理即可。受到情况3的启发，我们发现，通过将删除节点替换成前继节点或后继结点，且颜色不变，再考虑替换节点的删除，那么，最终情况2和情况3均可退化为情况1，处理起来就简单多了。 下面我们看看叶子节点删除有哪些情况 替换节点为红色 替换节点为黑色 叔叔节点为红色 叔叔节点为黑色 叔叔节点的子节点存在红节点 叔叔节点的子节点不存在红节点 情况1最简单，由于红节点移除不会导致替换节点方向黑节点数量减少，因此直接删除红节点即可。情况2中，删除替换节点会导致替换节点方向黑节点数量变少，因此整体思想是通过左旋、右旋、变色等方式将叔叔节点方向的红节点到替换节点方向，并将红节点变为黑色，补上减少的黑节点。 若叔叔节点方向有红节点，那么将红节点借到替换借到方向，并改为黑节点即可 情况2.2.2中，叔叔节点方向没有红节点，因此我们将叔叔节点变为红节点，这样，叔叔节点方向也会减少一个黑节点，那么替换节点删除后，祖父节点方向会减少一个黑节点，因此我们可以递归到处理祖父节点的黑节点减少问题上","link":"/2021/03/14/algo/10.rb_tree/"},{"title":"11. B树与B+树","text":"B树B树是一种多路平衡查找树，相对于二叉平衡树最多只有两个子节点，B树节点允许有多个子节点；在数据库索引的场景下，由于索引节点的加载需要读磁盘，读磁盘相对于内存处理是很慢的，若索引使用二叉数存储，那么查找的节点就会较多，需要磁盘加载的次数也会变多。因此，数据库索引一般使用多路平衡查找树，这能有效降低磁盘读取次数 B树特性如下： 每个节点上包含关键字、指向数据的指针和子节点的指针 节点上关键字以递增形式排列（可二分） M阶表示一个节点最多有M个查找路径，M&gt;=2 节点上关键字最多M-1个，最少ceil(M/2)-1个（ceil表示向上取整） 所有叶子节点都在同一层 节点插入我们不会细致的讲B树的算法，只做大概了解，B树通过节点合并和拆分达到重新平衡；下图模拟3、8、31、11、23、29、50、28的插入流程 节点删除 B+树B+树是B树的升级版，相对于B树，B+树的节点占用空间更少，查询更稳定。 B+树特性如下： B+树非叶子节点不保存数据，仅做索引，这样一来，节点所能保存的关键字大大增加 B+树的叶子节点保存了所有关键字已经对应的数据地址 B+树的叶子节点有序排列，且末尾保存了兄弟节点的指针 B+树的关键字数量=叶子节点数量（mysql是这么实现的，也有实现是关键字数量=叶子节点数量-1）","link":"/2021/03/15/algo/11.b_tree/"},{"title":"2. 冒泡排序","text":"算法简介 像鱼儿冒泡一样，每一轮遍历中，最大的元素将被交换到序列的末尾，最多遍历n-1次 每次遍历中，前后元素对比，若前一个元素大于后一个元素，则交换位置 代码如下： 12345678910111213141516public class BubbleSort extends Sort { @Override public void sort(int[] arr) { for (int i = 0; i &lt; arr.length - 1; i++) { for (int j = 0; j &lt; arr.length - 1 - i; j++) { if (arr[j] &gt; arr[j + 1]) { swap(arr, j, j + 1); } } } }}时间复杂度：O(n^2)空间复杂度：O(1)","link":"/2021/02/27/algo/2.bubble_sort/"},{"title":"3. 快速排序","text":"算法简介 分治法的思想，以一个位置作为基准，一次遍历完成后，基准位置左边的元素均小于基准元素，右边的元素均大于基准元素；以此递归 图其实挺难看的，看代码就很好理解的，代码如下： 12345678910111213141516171819202122232425262728293031323334public class QuickSort extends Sort { @Override public void sort(int[] arr) { quickSort(arr, 0, arr.length - 1); } private void quickSort(int[] arr, int left, int right) { if (left &gt;= right) { return; } int base = left; //每次遍历以最左边元素作为基准 int i = left; int j = right; while (i &lt; j) { while (arr[base] &lt;= arr[j] &amp;&amp; i &lt; j) { //以最左边元素作为基准时，必须右边先走 j--; } while (arr[base] &gt;= arr[i] &amp;&amp; i &lt; j) { i++; } if (i &lt; j) { swap(arr, i, j); } } swap(arr, base, i); quickSort(arr, left, i - 1); quickSort(arr, i + 1, right); }} 时间复杂度：O(nlogn)空间复杂度：O(1)注意：最坏情况下时间复杂度会达到O(n^2)，比如逆序的数组做顺序的排序，若使用第一个元素作为基准，每次排序基准元素都会被排到数组的边缘","link":"/2021/02/27/algo/3.quick_sort/"},{"title":"4. 归并排序","text":"算法简介 分治法的思想，两个有序的数组可归并为一个有序的数组，因此可将一个数组拆分为两个数组，两个数组再分别排序，形成两个有序的数组后，再通过归并算法合并为一个有序的数组；以此递归 若数组中只有一个元素，那么这个数组天然就是有序的 代码如下： 123456789101112131415161718192021222324252627282930313233343536public class MergeSort extends Sort { @Override public void sort(int[] arr) { System.arraycopy(mergeSort(arr, 0, arr.length - 1), 0, arr, 0, arr.length); } private int[] mergeSort(int[] arr, int left, int right) { if (left &gt; right) { throw new IllegalArgumentException(&quot;left is bigger than right&quot;); } if (left == right) { return new int[] {arr[left]}; } int mid = (left + right) / 2; return merge(mergeSort(arr, left, mid), mergeSort(arr, mid + 1, right)); } private int[] merge(int[] arr1, int[] arr2) { int[] arr = new int[arr1.length + arr2.length]; int idx = 0, idx1 = 0, idx2 = 0; while (idx1 &lt; arr1.length || idx2 &lt; arr2.length) { if (idx1 &gt;= arr1.length) { arr[idx++] = arr2[idx2++]; } else if (idx2 &gt;= arr2.length) { arr[idx++] = arr1[idx1++]; } else if (arr1[idx1] &lt;= arr2[idx2]) { arr[idx++] = arr1[idx1++]; } else { arr[idx++] = arr2[idx2++]; } } return arr; }} 时间复杂度：O(nlogn)空间复杂度：O(n)","link":"/2021/02/28/algo/4.merge_sort/"},{"title":"5. 堆排序","text":"算法简介 二叉堆是一种特别的数据结构，对于最小堆，他的每一个父节点都一定小于该节点的左右节点。 堆排序就是利用二叉堆的特性，不断移除堆顶元素，将其置于数组的尾部，从而实现数组最终有序 代码如下： 123456789101112131415161718192021222324252627282930313233343536public class HeapSort extends Sort { @Override public void sort(int[] arr) { //构建最大堆 for (int i = arr.length / 2 - 1; i &gt;= 0; i--) { down(arr, arr.length, i); } //移除堆顶元素到数组尾部 for (int len = arr.length - 1; len &gt; 0; len--) { swap(arr, 0, len); down(arr, len, 0); } } /** * idx节点下沉 */ private void down(int[] arr, int len, int idx) { int parentIdx = idx; int childIdx = (parentIdx * 2) + 1; while (childIdx &lt; len) { if (childIdx + 1 &lt; len &amp;&amp; arr[childIdx + 1] &gt; arr[childIdx]) { //找最大的子节点 childIdx++; } if (arr[parentIdx] &gt;= arr[childIdx]) { //下沉结束 return; } swap(arr, parentIdx, childIdx); parentIdx = childIdx; childIdx = (parentIdx * 2) + 1; } }} 时间复杂度：O(nlogn)空间复杂度：O(1)","link":"/2021/03/06/algo/5.heap_sort/"},{"title":"7. 跳表","text":"算法简介上文我们讲了二分查找，我们知道对于有序的数组，二分查找可以提高搜索效率，时间复杂度是O(logn)；如果我们将有序的数组替换成有序的链表，就用不了二分查找了，因为二分查找是基于数组下标的搜索；若要在有序列表搜索时达到类似二分查找的效果，我们需要的就是跳表；跳表通过给有序链表增加n级索引的方式，加快有序链表的搜索效率，数据结构如下图 若每隔两个节点新增一级索引，可以看出，整体搜索流程类似二分查找，所以跳表的时间复杂度也是O(logn) 但是跳表要怎么新增节点呢？如果我们的索引不变，新增的节点都集中在两个索引节点直接，就会导致跳表搜索退化为链表搜索 一种简单的办法就是每次新增节点都重建索引，但那样做新增节点的效率就会变差，为了在新增节点时维护索引，跳表引入了概率晋升；我们想象一下，如果新增一个节点时，这个节点有1/2的概率晋升到第一层索引，1/4的概率晋升到第二层索引…1/2^n晋升到第n层索引。那么只要节点数足够多，索引就会相对均匀，可以视为与每两个节点晋升一个索引等价。这样一来，我们就解决了新增节点同时维护索引的问题 作为一种数据结构，只增不减是不可能的，那么要怎么删除一个节点呢？删除节点相对来说就比较简单了，只要在链表和每层索引中删除对应节点即可 接下来我们看下代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class SkipList { private static final double PROMOTE_RATE = 0.5; //晋升概率 public Node head; public SkipList() { head = new Node(Integer.MIN_VALUE); } public Node search(int tar) { Node node = doSearch(tar); return node.data == tar ? node : null; } private Node doSearch(int tar) { Node cur = head; while (true) { if (cur.next != null &amp;&amp; cur.next.data &lt;= tar) { cur = cur.next; } else if (cur.down != null) { cur = cur.down; } else { break; } } return cur; } public void insert(int tar) { Node prev = doSearch(tar); if (prev.data == tar) { return; } Node cur = new Node(tar); prev.append(cur); Random random = new Random(); while (random.nextDouble() &lt; PROMOTE_RATE) { //概率晋升 while (prev.up == null &amp;&amp; prev.prev != null) { prev = prev.prev; } if (prev.up == null) { head = new Node(Integer.MIN_VALUE) ; prev.up(head); } prev = prev.up; Node promote = new Node(tar); prev.append(promote); cur.up(promote); cur = promote; } } public void delete(int tar) { Node node = search(tar); while (node != null) { node.prev.next = node.next; if (node.next != null) { node.next.prev = node.prev; } if (node.prev.data == Integer.MIN_VALUE &amp;&amp; node.prev.next == null &amp;&amp; node.prev.down != null) { //清理空的索引 head = node.prev.down; node.prev.down = null; head.up = null; return; } node = node.up; } } public class Node { public int data; public Node prev; public Node next; public Node up; public Node down; public Node(int data) { this.data = data; } public void append(Node node) { Node next = this.next; if (next == null) { this.next = node; node.prev = this; } else { this.next = node; node.prev = this; node.next = next; next.prev = node; } } public void up(Node node) { if (this.up != null) { throw new IllegalArgumentException(); } else { this.up = node; node.down = this; } } }} 跳表有较为广泛的工业应用，如redis中的有序列表就用到了跳表，redis的源码我们可以参考下，很多基础的数据结构redis都做的很好，适合学习","link":"/2021/03/08/algo/7.skip_list/"},{"title":"6. 二分查找","text":"算法简介在有序的数组中查找一个数，可使用二分查找算法，时间复杂度为O(logn) 代码如下： 1234567891011121314151617public class BinarySearch { public static int search(int[] arr, int tar) { int left = 0, right = arr.length - 1; while (left &lt;= right) { int mid = (left + right) / 2; if (arr[mid] == tar) { return mid; } else if (arr[mid] &lt; tar) { left = mid + 1; } else { right = mid - 1; } } return -1; }}","link":"/2021/03/08/algo/6.binary_search/"},{"title":"8. 二叉树","text":"算法简介二叉树中一个节点的左子树的所有节点一定小于这个节点的值，右子树的所有节点一定大于这个节点的值 查找节点查找节点比较简单，只需要从根节点开始，根据节点值大小往左子树方向或右子树方向查找，直到找到节点或子树为空为止 新增节点新增节点也比较简单，类似查找节点，根据节点值大小往左子树方向或右子树方向查找，直到找到节点或子树为空为止；若子树为空，则插入到对应位置 遍历二叉树遍历二叉树最常见的有三种方法，分别是前序遍历、中序遍历、后序遍历 前序遍历：当前节点 -&gt; 左子树 -&gt; 右子树 中序遍历：左子树 -&gt; 当前节点 -&gt; 右子树 后序遍历：左子树 -&gt; 右子树 -&gt; 当前节点 代码分为递归和栈两种写法，具体我就不讲了 删除节点若删除节点的左子树或右子树其一为空或者左右子树都为空，那么删除节点很简单 如果删除节点的左右节点都不为空，那就比较复杂 整体思想是找到删除节点右子树中最小的节点，根据二叉树的特性可知，遍历删除节点右子树的左子树方向的节点，直到节点的左子树为空，那么这个节点一定是删除节点右子树中最小的节点，且这个节点的左子树为空，这有利于这个节点的删除；将最小节点和删除节点互换，再删除节点并将原最小节点的右子树接到删除节点的位置即可 下面我们来梳理一下这些情况： 左右子树均为空 左子树为空或右子树为空 左右子树均不为空 接下来我们看代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class BinaryTree { private Node root; public void insert(int data) { if (root == null) { root = new Node(data); return; } Node parent = root; while (true) { if (parent.data == data) { return; } else if (parent.data &gt; data) { if (parent.left == null) { parent.left = new Node(data); parent.left.parent = parent; return; } else { parent = parent.left; } } else { if (parent.right == null) { parent.right = new Node(data); parent.right.parent = parent; return; } else { parent = parent.right; } } } } public Node search(int data) { Node cur = root; while (cur != null) { if (cur.data == data) { return cur; } else if (cur.data &gt; data) { if (cur.left == null) { return null; } else { cur = cur.left; } } else { if (cur.right == null) { return null; } else { cur = cur.right; } } } return null; } public void delete(int data) { Node cur = search(data); if (cur == null) { return; } if (cur.left == null &amp;&amp; cur.right == null) { if (cur.parent == null) { root = null; } else if (cur.parent.left == cur) { cur.parent.left = null; } else { cur.parent.right = null; } } else if (cur.left == null) { if (cur.parent == null) { root = cur.right; } else if (cur.parent.left == cur) { cur.parent.left = cur.right; } else { cur.parent.right = cur.right; } } else if (cur.right == null) { if (cur.parent == null) { root = cur.left; } else if (cur.parent.left == cur) { cur.parent.left = cur.left; } else { cur.parent.right = cur.left; } } else { Node next = cur.right; if (next.left == null) { cur.right = next.right; cur.data = next.data; return; } while (next.left != null) { //找右子树中最小的节点 next = next.left; } cur.data = next.data; next.parent.left = next.right; } } public static class Node { public int data; public Node parent; public Node left; public Node right; public Node(int data) { this.data = data; } }}","link":"/2021/03/09/algo/8.binary_tree/"},{"title":"9. AVL树","text":"算法简介我们想象一下，如果将一个有序数组依序添加到二叉树中，那么这颗树的所有节点都会集中到一个方向，类似链表；这种情况下，二叉树的搜索会退化为链表的搜索 为了避免这种情况，就有了平衡树。AVL树就是一种平衡树，树上任意节点的左节点和右节点深度相差都不大于1 添加节点AVL树添加节点流程和二叉树一致，当AVL树失衡时，通过旋转失衡最小子树，可以让AVL树重新达到平衡 失衡分为四种情况： LL：左子树深度大于右子树深度，且左孩子的左子树深度大于右子树深度 LR：左子树深度大于右子树深度，且左孩子的右子树深度大于左子树深度 RR：右子树深度大于左子树深度，且右孩子的右子树深度大于左子树深度 RL：右子树深度大于左子树深度，且右孩子的左子树深度大于右子树深度 LL右旋即可 RR左旋即可 LR左孩子左旋，可将LR转换为LL RL右孩子右旋，可将RL转换为RR 删除节点删除节点也是建立在二叉树节点的删除之上的，节点删除后，同样需要对AVL树进行重新平衡。和添加节点不同的是，添加节点往往只需要一次平衡即可使AVL树重新达到平衡，而删除节点后，如果我们删除了树深度较小的子树的节点，平衡后会导致数深度更小，因此需要在父节点再做平衡，直到AVL树达到平衡","link":"/2021/03/10/algo/9.avl_tree/"},{"title":"1.内存分布","text":"JVM内存区域包括 PC计数器、Java虚拟机栈、本地方法栈、堆、方法区、运行时常量池和直接内存 PC计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码行号指示器，由线程私有 虚拟机栈线程私有内存空间，它的生命周期和线程相同。线程执行期间，每个方法执行时都会创建一个栈帧(Stack Frame) ，用于存储 局部变量表、操作数栈 、动态链接 、方法出口等信息 局部变量表：用于存储方法参数和局部变量；在编译期间分配内存空间，可以存放以下编译期的变量类型 基本数据类型：boolean, byte, char, short, int, float, long, double等8种 对象引用类型 ：reference，指向对象起始地址的引用指针 返回地址类型 ：returnAddress，返回地址的类型 操作数栈：虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用 动态链接：每个栈帧都包含一个指向运行时常量池中所属的方法引用，持有这个引用是为了支持方法调用过程中的动态链接 静态解析：一部分会在类加载阶段或第一次使用的时候转化为直接引用（如final、static域等） 动态解析：另一部分将在每一次的运行期间转化为直接引用 方法返回地址 正常返回：当执行遇到返回指令，会将返回值传递给上层的方法调用者 异常返回：当执行遇到异常，并且当前方法体内没有得到处理，就会导致方法退出 当一个方法返回时，可能依次进行以下3个操作： 1. 恢复上层方法的局部变量表和操作数栈。 2. 把返回值压入调用者栈帧的操作数栈。 3. 将PC计数器的值指向下一条方法指令位置 在Java虚拟机规范中，对这个区域规定了两种异常 如果当前线程请求的栈深度大于虚拟机栈所允许的深度，将会抛出StackOverflowError异常（不允许动态拓展的情况下） 如果扩展时无法申请到足够的内存空间，就会抛出 OutOfMemoryError 异常 本地方法栈本地方法栈和Java虚拟机栈作用相似，主要区别是Java虚拟机栈执行的是Java方法，而本地方法栈执行Native方法 堆堆由所有线程共享，用于存放对象实例，几乎所有的对象实例都在这里分配内存。 在Java中，为了更好的管理堆中对象的分配和回收，往往采用分代模型（详情参考垃圾回收章节） 新生代 (Young Generation) Eden区：对象首先进入Eden区 Survivor区：有2个Survivor区，用于对象复制；前几次回收，存活对象由Eden区转移到Survivor区，再在两个Survivor区不断交换 老年代 (Old Generation) ：在Survivor区的对象经历若干次收集仍然存活的，就会被转移到老年代Old中 方法区（Hotspot上称为永久代）方法区和Java堆一样，为多个线程共享，它用于存储类信息、常量、静态常量和即时编译后的代码等数据 jdk8中，永久代改为元空间（Metaspace），使用直接内存进行管理；永久代大小受限于-XX:MaxPermSize，而元空间的容量可以动态扩缩 运行时常量池运行时常量池是方法区的一部分，Class文件中除了有类的版本、字段、方法和接口等描述信息外， 还有一类信息是常量池，用于存储编译期间生成的各种字面量和符号引用 直接内存直接内存不属于虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。例如Java NIO允许Java程序直接访问直接内存，通常直接内存的速度会优于Java堆内存。因此，对于读写频繁、性能要求高的场景，可以考虑使用直接内存。这往往也是最容易发生内存泄漏的地方 相关JVM参数 -Xms：堆的最小内存 -Xmx：堆的最大内存（经验上设置堆得最大内存为机器内存的2/3） -Xss：栈内存大小 -XX:+HeapDumpOnOutOfMemoryError：虚拟机在出现内存溢出异常时Dump出内存堆运行时快照 -XX:PermSize：方法区最小内存 -XX:MaxPermSize：方法区最大内存 -XX:MaxDirectMemorySize：直接内存大小 -XX:MetaspaceSize：首次元空间GC的阈值 -XX:MaxMetaspaceSize：元空间的最大空间，默认是没有限制的 -XX:MinMetaspaceFreeRatio：在GC之后，元空间的空闲容量占比阈值，小于该占比会导致GC阈值提升 -XX:MaxMetaspaceFreeRatio：在GC之后，元空间的空闲容量占比阈值，大于该占比会导致GC阈值下降 -XX:MinMetaspaceExpansion：GC阈值最小增长 -XX:MaxMetaspaceExpansion：GC阈值最大增长（找个时间实验一下！！！） 问题排查堆内存溢出Heap OOM（OutOfMemoryError: Java heap space）通常要考虑内存泄露和内存溢出两种可能性 内存泄露：使用Java VisualVM工具进行分析，查看泄露对象是通过怎样的路径与GC Roots关联而导致垃圾回收器无法回收的。 内存溢出：使用Java VisualVM工具分析，不存在泄露对象，也就是说堆内存中的对象必须得存活着。就要考虑如下措施： 从代码上检查是否存在某些对象生命周期过长、持续状态时间过长的情况，尝试减少程序运行期的内存 检查虚拟机的堆参数(-Xmx与-Xms)，对比机器的物理内存看是否还可以调大 虚拟机和本地方法栈溢出关于虚拟机栈和本地方法栈，分析内存异常类型可能存在以下两种： 如果现场请求的栈深度大于虚拟机所允许的最大深度，或是栈上局部变量过多，将抛出StackOverflowError异常。 如果虚拟机在扩展栈时无法申请到足够的内存空间，可能会抛出java.lang.OutOfMemoryError: unable to create new native thread 运行时常量池/方法区溢出java.lang.OutOfMemoryError: PermGen space","link":"/2021/04/19/jvm/1.memory/"},{"title":"2. G1垃圾回收（GC）","text":"怎样的对象可以回收 引用计数：循环引用无法回收 可达性分析(root-tracing)：root可达的节点都是活节点，root节点包括 栈中的节点 方法区静态对象引用的节点 方法区的常量引用的节点 本地方法栈引用的节点 引用类型 强引用：类似Object obj = new Object()，存在强引用则不会被回收 弱引用：可用WeakReference类实现，下次垃圾回收时被回收 虚引用：垃圾回收时可收到通知 软引用：可用SoftReference类实现，内存即将溢出时可回收 方法区的收集时机 该类对象已经全部被回收 classloader已经被回收 无法通过任何方法访问该类 垃圾收集算法标记-清除法标记-清除算法对根集合进行扫描，对存活的对象进行标记。标记完成后，再对整个空间内未被标记的对象扫描，进行回收。 这存在一个缺点：容易造成内存碎片，导致空间足够但大对象无法分配 复制算法这常用于新生代的垃圾收集，将新生代分为Eden，from，to三个区，不通过jvm参数指定时默认比例8:1:1。 回收时，将eden区可达对象和from区可达对象移到to区，然后进行清理。有以下几种情况，对象会被移到老年代： 如果对象过大，则移到老年代（Tenured） from区可达对象年龄超过jvm参数指定的年龄（默认15），移到老年代 如果对象大于from区大小*jvm参数指定的阈值，移到老年代 缺点是可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制 标记-整理算法标记-整理算法 采用和 标记-清除算法 一样的方式进行对象的标记，但后续不直接对可回收对象进行清理，而是将所有的 存活对象 往一端 空闲空间 移动，然后清理掉端边界以外的内存空间 这解决了标记-清理算法存在的内存碎片问题，但需要进行局部对象移动，一定程度上降低了效率 分代收集模型当代大多数的垃圾回收器都使用分代模型，将堆内存分为新生代和老年代 新生代 (Young Generation) Eden区：对象首先进入Eden区 Survivor区：有2个Survivor区，用于对象复制；前几次回收，存活对象由Eden区转移到Survivor区，再在两个Survivor区不断交换 老年代 (Old Generation) ：在Survivor区的对象经历若干次收集仍然存活的，就会被转移到老年代Old中 垃圾收集器Serial单线程的新生代收集器，采用复制算法 ParNew多线程的新生代收集器，采用复制算法 ParallelScavenge多线程的新生代收集器，采用复制算法；更关注吞吐量高 ParallelOld多线程的老年代收集器，采用标记-整理算法；更关注吞吐量 SerialOld单线程的老年代收集器，采用标记-整理算法。是CMS等并发收集器的后备方案 CMS支持并发的老年代收集器，采用标记-清除算法 步骤如下： 初始标记（STW）：标记root（可达性分析中的节点+新生代节点）可达的第一个节点 并发标记：标记从初始标记可达的节点，将变化的可达节点标为dirty 重新标记（STW）：重新标记dirty的节点 并发清除：清除标记为不可达的节点 触发Minor GC的时机：达到阈值即触发回收，而不是等到满；若清理过程中内存不足，将触发一次Full GC，退化为使用SerialOld进行收集 CMS收集器不能和ParallelScavenge合作，因为吞吐量优先和停顿时间优先是背道而驰的 由于CMS会产生过多的内存碎片，因此一定次数后悔使用SerialOld的进行一次FullGC G1收集器支持并发的新生代和老生代收集器，采用复制算法，在Region之间进行复制，一定程度上回避了了复制算法效率低的问题 内存模型G1收集器将堆分成Region，逻辑上区分Eden、Survivor、Old、Humongous（大对象，可以算作Old的一部分）、unuse，因此G1也是基于分代模型的 G1是智能的，一般不需要设置太复杂的JVM参数，G1会智能的调整堆大小和新生代、老年代占比，按我们设置的停顿时间作为目标进行回收，优先收集垃圾最多的Region 内存耗尽，G1先尝试扩容。达到-Xmx设置的堆大小最大值后，新生代耗尽就会触发新生代的回收。若老年代内存超过阈值，则会触发一次Mixed GC，阈值由-XX:InitiatingHeapOccupancyPercent决定；若清理过程中内存不足，将触发一次Full GC，退化为使用SerialOld进行收集 Region由n个Card组成，一个对象分配n个连续的Card。若对象大小超过Region大小的一半，则为大对象（Humongous），Region类型为Humongous，可看做老年代，会分配一个或多个Region。G1对大对象的回收做了优化，若对象不可达，可在Young GC时回收 详情参考：Getting Started with the G1 Garbage Collector 一些概念 TLAB，线程的本地分配缓冲，属于Eden区 PLAB，GC的晋升本地分配缓冲，属于Suvivor或老生代 RSet，只有老生代Region才有，记录哪个分区的哪个Card的对象引用本分区的对象，避免老生代的回收需要扫描全堆 维护方式： 栅栏，一个赋值操作进行前（写前栅栏），引用-1 赋值完成后（写后栅栏），引用+1，通过批量操作更新RSet STAB（起始快照算法），维护逻辑上的堆引用图，用于并发标记期间更新RSet 三色标记法，黑色是自己和子节点存活，灰色是自己存活，白色是非存活 引用变更时进到变更队列，出队时把该节点标为非白 并发优化（Refinement）线程负责更新RSet，如果来不及处理会停止应用线程（发生在任意时刻） 总结：栅栏时引用写入缓冲区，并发优化线程读取缓冲区更新RSet PRT（Per Region Table），避免被引用多的分区的RSet太大，会区分粒度的记录引用 记录Card 记录引用对象的分区 只记录某个分区有没有引用 并发标记线程：通过PTAMS和NTAMS标记已完成标记的区域和下次标记的区域，使用previous和next位图标记存活对象（只发生在并发标记期间） 新生代回收新生代回收采用复制算法，多个Region上的垃圾对象被清理后，会被复制到新的Region上，解决内存碎片的问题。本质上和其他回收器没有区别 老年代回收步骤如下： 初始标记（STW）：和youngGC一起（好处是并发根分区扫描时减少youngGC的概率），通过RSET找到root Rigion，通过root region找root节点 根分区扫描：把SUVIVOR分区的节点标为根，此时如果有youngGC会等根分区扫描完成 并发标记：并发标记线程标记存活对象，这个阶段空region会立即回收掉，并发优化线程处理RSet变化，计算存活率 重新标记（STW）：这个阶段需要完成标记堆上的存活对象，处理在并发标记阶段未处理的RSet，采用STAB算法 清除（STW）：回收空region，交换PTAMS和NTAMS，previous位图和next位图，入CSET，之后就可以进行MixedGC，回收到足够多的Region后结束 复制：将存活对象复制到新的Region上，解决内存碎片问题。这往往伴随着一次Young GC GC相关的JVM参数 -XX:+PrintGCDetails：打印GC日志 -XX:NewRatio：设置新生代和老年代比例（G1不建议使用） -XX:NewSize：设置新生代大小（G1不建议使用） -XX:MaxNewSize：设置新生代最大大小（G1不建议使用） -XX:CMSFullGCsBeForeCompaction：n次CMS后触发FullGC -XX:GCTimeRatio：GCtime占比，CMS默认99，G1默认9 -XX:+UseG1GC：开启G1 -XX:MaxGCPauseMillis=200：期望的最大STW时间，默认200ms -XX:InitiatingHeapOccupancyPercent=45：回收老生代的阈值，老年代达到阈值即开始并发标记，默认45% -XX:ConcGCThreads=n：设置并发标记的线程数，默认值看不同平台 -XX:G1ReservePercent=n：为晋升保留的空间，默认为10% -XX:SurvivorRatio=n：设置eden/survivro，默认为8 -XX:MaxTenuringThreshold=n：最大晋升阈值，默认为15 -XX:ParallelGCThreads=n：新生代收集的线程数，默认值看不同平台 -XX:G1HeapRegionSize=n：最小1MB，最大32MB，默认值看堆大小，堆大小除以2048 -XX:G1NewSizePercent：最小新生代比例，默认5% -XX:G1MaxNewSizePercent：最大新生代比例，默认60% -XX:G1MixedGCLiveThresholdPercent：活跃度小于阈值，才进入CSET，默认65% -XX:G1OldCSetRegionThresholdPercent=10：进入CSET的老生带Region占用内存最大值，默认10% -XX:G1MixedGCCountTarget=8：MixGc的最大次数 -XX:G1HeapWastePercent=10：可回收百分比小于阈值不回收，默认10%","link":"/2021/02/24/jvm/2.gc/"},{"title":"4.类加载机制","text":"类加载过程类加载器简言之，就是用于把.class文件中的字节码信息转化为具体的java.lang.Class对象的过程的工具 类加载的过程分为三个步骤(五个阶段) ：加载 -&gt; 连接（验证、准备、解析）-&gt; 初始化。 加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段可以在初始化阶段之后发生，也称为动态绑定或晚期绑定。 加载：查找并加载类的二进制数据的过程；通过类的全限定名找到.class文件，读取字节流，在方法区生成运行时数据结构，在堆中生成Class对象，作为方法区中数据范文的入口 连接 验证：确保Class字节流中的信息是否符合虚拟机的要求 准备：为类的静态变量分配内存（只分配内存，不做初始化） 解析：符号引用转换为直接饮用 初始化：为静态变量赋值，执行静态代码块；通过new关键字、Class.forName(“xxx”)、访问静态变量、静态方法都会触发初始化；初始化子类会先进行父类的初始化 注意：以下三种被动引用的方式不会触发类的初始化！！！ 通过子类访问父类的静态变量或静态方法 访问常量 定义数组引用而不赋值 类加载器与双亲委派类加载器之间存在层级关系，BootstrapClassloader是所有类加载器的源头，它负责加载ExtClassLoader和AppClassLoader，并指定他们的父加载器 BootstrapClassloader：负责加载JAVA_HOME/lib下的类 ExtClassLoader：负责加载JAVA_HOME/lib/ext下的类 AppClassLoader：负责加载自定义的类 每个类装载器都有一个自己的命名空间用来保存已装载的类，并通过命名空间和全局限定名保证类的唯一性（ClassLoader + PackageName + ClassName）；包名和类名相同的类由不同的类加载器进行加载出来并不是相同的类，实例化的对象不能进行类型转换；这就是类加载器的隔离机制 为了实现隔离，JVM引入了双亲委派的机制（先检查当前类加载器是否已加载该类，若未加载，则优先由父加载器尝试加载），具体过程如下： AppClassLoader发现自己未加载该类，将类加载请求委派给ExtClassLoader ExtClassLoader发现自己未加载该类，将类加载请求委派给BootstrapClassLoader BootstrapClassLoader加载失败，会使用ExtClassLoader进行加载 ExtClassLoader加载失败，则由AppClassLoader尝试加载 AppClassLoader也加载失败，则抛出ClassNotFoundException 代码如下： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 类的动态加载Class.forName()：把类的.class文件加载到JVM中，对类进行解释的同时执行类中的static静态代码块；ClassLoader.loadClass()：只是把.class文件加载到JVM中，不会执行static代码块中的内容，只有在newInstance才会去执行 对象的初始化顺序静态变量/静态代码块 -&gt; 普通代码块 -&gt; 构造函数 父类静态变量和静态代码块（先声明的先执行） 子类静态变量和静态代码块（先声明的先执行）； 父类普通成员变量和普通代码块（先声明的先执行）； 父类的构造函数； 子类普通成员变量和普通代码块（先声明的先执行）； 子类的构造函数。","link":"/2021/04/19/jvm/4.classloader/"},{"title":"10. 正则表达式匹配","text":"思路：动态规划；首先需要设计一个状态数组f[i][j]用于表示p的前i位与s的前j位是否匹配（注意：i与j可以为0，因为p存在*的场景下，p可以匹配空字符串），状态转移分为以下情况（注意边界）： if i == 0： if j == 0: f[i][j] = true else: f[i][j] = false if i == 1: if j == 1 &amp;&amp; match(s[j - 1], p[i - 1]): f[i][j] = true else: f[i][j] = false if j == 0: if p[i - 1] == ‘*’: f[i][j] = f[i - 2][j] else: f[i][j] = false if match(s[j - 1], p[i - 1]): f[i][j] = f[i - 1][j - 1] if p[j - 1] == ‘*’: if match(s[j - 1], p[i - 2]): f[i][j] = f[i - 1][j] else f[i][j] = f[i - 2][j] else: f[i][j] = false 1234567891011121314151617181920212223242526272829303132class Solution { public boolean isMatch(String s, String p) { boolean[][] reg = new boolean[p.length() + 1][s.length() + 1]; for (int i = 0; i &lt;= p.length(); i++) { for (int j = 0; j &lt;= s.length(); j++) { if (i == 0) { reg[i][j] = j == 0; continue; } else if (i == 1) { if (p.charAt(i - 1) == '*') { throw new IllegalArgumentException(&quot;p首位不允许为*&quot;); } else { reg[i][j] = j == 1 &amp;&amp; (p.charAt(i - 1) == '.' || p.charAt(i - 1) == s.charAt(j - 1)); } } else if (j == 0) { reg[i][j] = p.charAt(i - 1) == '*' &amp;&amp; reg[i - 2][j]; } else { if (p.charAt(i - 1) == '.') { reg[i][j] = reg[i - 1][j - 1]; } else if (p.charAt(i - 1) == '*') { reg[i][j] = ((p.charAt(i - 2) == '.' || p.charAt(i - 2) == s.charAt(j - 1)) &amp;&amp; reg[i][j - 1]) || reg[i - 2][j]; } else { reg[i][j] = s.charAt(j - 1) == p.charAt(i - 1) &amp;&amp; reg[i - 1][j - 1]; } } } } return reg[p.length()][s.length()]; }}","link":"/2021/03/19/leetcode/10.regex/"},{"title":"11. 乘最多水的容器","text":"思路：双指针法；将i和j指向数组的两端，当height[i] &lt; height[j]时，i++，否则j–；这样做的原理是什么呢？我们把问题转换为数组搜索，我们的目的是搜索最大的area(i, j) = min(i, j) * (j-i)。此时，若取i，那么必须存在i &lt; k &lt; j使得area(i, k) &lt; area(i, j)；由于i相对j小，因此min(i, j) = height[i]，而min(i, k) &lt;= height[i]，又有k &lt; j，因此area(i, k) &lt; area(i, j)，i可以排除，因此应该移动i指针 123456789101112131415161718192021class Solution { public int maxArea(int[] height) { if (height.length &lt; 2) { return 0; } int i = 0, j = height.length - 1, max = 0; while (i &lt; j) { int area = (j - i) * Math.min(height[i], height[j]); if (max &lt; area) { max = area; } if (height[i] &lt; height[j]) { i++; } else { j--; } } return max; }}","link":"/2021/03/21/leetcode/11.max_area/"},{"title":"15. 三数之和","text":"思路如下：固定一个数，可将该问题转换为两数之和。若数组有序，两数之和问题可用双指针法，复杂度为O(n)；若数组无序，可用hash数组存储已经遍历过的数值O(n)，但需要额外的空间进行存储在三数之和问题中，由于需要固定一个数，因此复杂度为O(n^2)；可以先进行排序，再使用双指针法，降低空间复杂度 123456789101112131415161718192021class Solution { public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { Set&lt;List&lt;Integer&gt;&gt; groups = new HashSet&lt;&gt;(); Arrays.sort(nums); for (int i = 0; i &lt; nums.length - 2; i++) { int j = i + 1, k = nums.length - 1, sum = 0 - nums[i]; while (j &lt; k) { if (sum == nums[j] + nums[k]) { groups.add(Arrays.asList(nums[i], nums[j], nums[k])); k--; j++; } else if (nums[j] + nums[k] &gt; sum) { k--; } else { j++; } } } return new ArrayList&lt;&gt;(groups); }}","link":"/2021/03/21/leetcode/15.three_sum/"},{"title":"17. 电话号码的字母组合","text":"思路：回溯法；回溯遍历即可，不多讲 12345678910111213141516171819202122232425262728293031class Solution { public List&lt;String&gt; letterCombinations(String digits) { if (digits.length() == 0) { return Collections.emptyList(); } Map&lt;String, List&lt;String&gt;&gt; digit2Letters = new HashMap&lt;&gt;(); digit2Letters.put(&quot;2&quot;, Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)); digit2Letters.put(&quot;3&quot;, Arrays.asList(&quot;d&quot;, &quot;e&quot;, &quot;f&quot;)); digit2Letters.put(&quot;4&quot;, Arrays.asList(&quot;g&quot;, &quot;h&quot;, &quot;i&quot;)); digit2Letters.put(&quot;5&quot;, Arrays.asList(&quot;j&quot;, &quot;k&quot;, &quot;l&quot;)); digit2Letters.put(&quot;6&quot;, Arrays.asList(&quot;m&quot;, &quot;n&quot;, &quot;o&quot;)); digit2Letters.put(&quot;7&quot;, Arrays.asList(&quot;p&quot;, &quot;q&quot;, &quot;r&quot;, &quot;s&quot;)); digit2Letters.put(&quot;8&quot;, Arrays.asList(&quot;t&quot;, &quot;u&quot;, &quot;v&quot;)); digit2Letters.put(&quot;9&quot;, Arrays.asList(&quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;)); return letterCombinations(digits, &quot;&quot;, digit2Letters); } private List&lt;String&gt; letterCombinations(String digits, String combination, Map&lt;String, List&lt;String&gt;&gt; digit2Letters) { if (digits.length() == 0) { return Arrays.asList(combination); } if (!digit2Letters.containsKey(digits.substring(0, 1))) { return letterCombinations(digits.substring(1), combination, digit2Letters); } List&lt;String&gt; conbinations = new ArrayList&lt;&gt;(); for (String c : digit2Letters.get(digits.substring(0, 1))) { conbinations.addAll(letterCombinations(digits.substring(1), combination + c, digit2Letters)); } return conbinations; }}","link":"/2021/03/21/leetcode/17.letter_groups/"},{"title":"1. 浅谈I&#x2F;O","text":"一些概念在讲I/O前，我们先讲一些操作系统的基础知识 用户空间与内核空间现在操作系统都是采用虚拟存储器，以32位操作系统为例，它的寻址空间（虚拟存储空间）为4G（2^32）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 缓存I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 有个缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 缓存IO对我们后面讲IO模式帮助很大 I/O模式对一次I/O而言，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。也就是说，它会经历两个阶段： 等待数据准备 将数据从内核拷贝到进程中 正式因为这两个阶段，linux系统产生了下面五种I/O模式的方案 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以这只提及剩下的四种I/O模式 阻塞 I/O进程进行系统调用后，即进入阻塞；内核开始准备数据，并将数据从内核空间拷贝到用户空间；之后，用户进程才接触阻塞，可以读取数据 非阻塞 I/O进程可以设置socket为非阻塞，进行系统调用后，不会进入阻塞状态；若内核未准备好数据，则返回一个error，进程接收到error，则会发起下一次系统调用；若内核数据准备就绪，则将数据从内核空间拷贝到用户空间，然后返回 这种IO模式的特点就是进程需要不断轮询内核数据是否准备就绪 注意：非阻塞I/O在内核将数据从内核空间拷贝到用户空间时，是阻塞的！！！ I/O多路复用多路复用就是我们常说的select、poll、epoll，也称为事件驱动的IO模式，本质上是对非阻塞IO的一种封装 它的基本原理就是select、poll、epoll这些函数会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程 异步 I/O进程发起I/O操作后，可以立刻开始去做其它的事。内核会等待数据准备完成，然后将数据从内核空间拷贝到用户空间，完成后，内核才给进程发送一个signal，告诉它I/O操作已经完成 系统调用下面讲讲I/O多路复用相关的系统调用，详情参考系统调用手册：https://www.kernel.org/doc/man-pages/ select详情参考：https://man7.org/linux/man-pages/man2/select.2.html 1234567891011/** * select支持监控多个文件描述符，阻塞知道到文件描述符就绪或超时 注意：监控的文件描述符数量最多1024个！由于调用后需要遍历文件描述符列表，所以性能较差！ * * nfds：文件描述符数量 * readfds：需要监控是否可读的文件描述符 * writefds：需要监控是否可写的文件描述符 * exceptfds：返回可读写的文件描述符 * timeout：超时 */int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); poll详情参考：https://man7.org/linux/man-pages/man2/poll.2.html 1234567891011121314struct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */};/** * poll和select没有本质的区别，调用后仍然需要遍历文件描述符列表，随着监控的文件描述符数量增长，性能线性下降 * * fds：文件描述符以及需要监控的事件 * nfds：文件描述符数量 * timeout：超时 */int poll(struct pollfd *fds, nfds_t nfds, int timeout); epoll接下来我们看看epoll，epoll分为三个系统调用 epoll_create详情参考：https://man7.org/linux/man-pages/man2/epoll_create.2.html 1234/** * 创建一个epoll文件描述符，用于监听 需要监听读写事件的文件描述符 是否就绪 */int epoll_create(int size); epoll_ctl详情参考：https://man7.org/linux/man-pages/man2/epoll_ctl.2.html 123456789101112131415161718192021/** * 在epoll文件描述符上注册需要监听的文件描述符 * * epfd：epoll文件描述符 * op：操作类型，增、删、改 * fd：需要监听的文件描述符 * event：需要监听的事件 */int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ //调用epoll_wait后同时返回该data};typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64;} epoll_data_t; epoll_wait详情参考：https://man7.org/linux/man-pages/man2/epoll_wait.2.html 123456789/** * 调用epoll_wait后，阻塞直到有文件描述符就绪 * * epfd：epoll文件描述符 * events：返回已就绪的文件描述符 * maxevents：本次调用返回的最大事件数 * timeout：超时 */int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116#define IPADDRESS &quot;127.0.0.1&quot;#define PORT 8787#define MAXSIZE 1024#define LISTENQ 5#define FDSIZE 1000#define EPOLLEVENTS 100listenfd = socket_bind(IPADDRESS,PORT);struct epoll_event events[EPOLLEVENTS];//创建一个描述符epollfd = epoll_create(FDSIZE);//添加监听描述符事件add_event(epollfd,listenfd,EPOLLIN);//循环等待for ( ; ; ){ //该函数返回已经准备好的描述符事件数目 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); //处理接收到的连接 handle_events(epollfd,events,ret,listenfd,buf);}//事件处理函数static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf){ int i; int fd; //进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。 for (i = 0;i &lt; num;i++) { fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) &amp;&amp;(events[i].events &amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events &amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events &amp; EPOLLOUT) do_write(epollfd,fd,buf); }}//添加事件static void add_event(int epollfd,int fd,int state){ struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&amp;ev);}//处理接收到的连接static void handle_accpet(int epollfd,int listenfd){ int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)&amp;cliaddr,&amp;cliaddrlen); if (clifd == -1) perror(&quot;accpet error:&quot;); else { printf(&quot;accept a new client: %s:%d\\n&quot;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); } }//读处理static void do_read(int epollfd,int fd,char *buf){ int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) { perror(&quot;read error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 } else if (nread == 0) { fprintf(stderr,&quot;client close.\\n&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 } else { printf(&quot;read message is : %s&quot;,buf); //修改描述符对应的事件，由读改为写 modify_event(epollfd,fd,EPOLLOUT); } }//写处理static void do_write(int epollfd,int fd,char *buf) { int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1){ perror(&quot;write error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLOUT); //删除监听 }else{ modify_event(epollfd,fd,EPOLLIN); } memset(buf,0,MAXSIZE); }//删除事件static void delete_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&amp;ev);}//修改事件static void modify_event(int epollfd,int fd,int state){ struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&amp;ev);} Java NIO编程Api和系统调用相似，直接看demo 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class NioEchoServer { private static final int BUF_SIZE = 256; private static final int TIMEOUT = 3000; public static void main(String args[]) throws Exception { // 打开服务端 Socket ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 打开 Selector Selector selector = Selector.open(); // 配置为非阻塞模式 serverSocketChannel.configureBlocking(false); // 将 channel 注册到 selector 中. // 通常我们都是先注册一个 OP_ACCEPT 事件, 然后在 OP_ACCEPT 到来时, 再将这个 Channel 的 OP_READ // 注册到 Selector 中. serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); // 服务端 Socket 监听8080端口 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); while (true) { // 通过调用 select 方法, 阻塞地等待 channel I/O 可操作 if (selector.select(TIMEOUT) == 0) { System.out.print(&quot;.&quot;); continue; } // 获取 I/O 操作就绪的 SelectionKey, 通过 SelectionKey 可以知道哪些 Channel 的哪类 I/O 操作已经就绪. Iterator&lt;SelectionKey&gt; keyIterator = selector.selectedKeys().iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); // 当获取一个 SelectionKey 后, 就要将它删除, 表示我们已经对这个 IO 事件进行了处理. keyIterator.remove(); if (key.isAcceptable()) { // 当 OP_ACCEPT 事件到来时, 我们就有从 ServerSocketChannel 中获取一个 SocketChannel, // 代表客户端的连接 // 注意, 在 OP_ACCEPT 事件中, 从 key.channel() 返回的 Channel 是 ServerSocketChannel. // 而在 OP_WRITE 和 OP_READ 中, 从 key.channel() 返回的是 SocketChannel. SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept(); clientChannel.configureBlocking(false); //在 OP_ACCEPT 到来时, 再将这个 Channel 的 OP_READ 注册到 Selector 中. // 注意, 这里我们如果没有设置 OP_READ 的话, 即 interest set 仍然是 OP_CONNECT 的话, 那么 select 方法会一直直接返回. // 注意！！！此处可以设置attachment clientChannel.register(key.selector(), OP_READ, ByteBuffer.allocate(BUF_SIZE)); } if (key.isReadable()) { SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buf = (ByteBuffer) key.attachment(); long bytesRead = clientChannel.read(buf); if (bytesRead == -1) { //客户端连接关闭 //连接关闭会将selectionKey加入到cancelKeys clientChannel.close(); } else if (bytesRead &gt; 0) { key.interestOps(OP_READ | SelectionKey.OP_WRITE); System.out.println(&quot;Get data length: &quot; + bytesRead); } } if (key.isValid() &amp;&amp; key.isWritable()) { ByteBuffer buf = (ByteBuffer) key.attachment(); buf.flip(); SocketChannel clientChannel = (SocketChannel) key.channel(); clientChannel.write(buf); if (!buf.hasRemaining()) { key.interestOps(OP_READ); } buf.compact(); } } } }}","link":"/2021/03/02/netty/1.io/"},{"title":"2. Netty总览","text":"Netty是什么Netty是一个基于事件驱动理念设计的传输层网络编程框架，它极大简化了TCP、UDP编程，并封装了HTTP、WebSocket等多种常见的应用层协议，让Java开发者可以快速开发易维护的高性能服务端和客户端 快速入门首先，我们构建一个极简的C/S应用，来感受Netty的魅力。 客户端将以请求的形式传输一个字符串给服务端，而服务端要做的就是将这个字符串返回给客户端，我们称这个协议为echo协议 服务端12345678910111213141516171819202122232425262728293031323334353637public class EchoServer { private int port; public EchoServer(int port) { this.port = port; } public void run() throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); //监听accept事件的eventloop EventLoopGroup workerGroup = new NioEventLoopGroup(); //监听read、write等事件的eventloop try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) //注册eventloop .channel(NioServerSocketChannel.class) //TCP NIO模式 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { //将EchoServerHandler这个hander添加到pipeline中，eventloop监听到事件后，依次回调pipeline上的每个handler ch.pipeline().addLast(new EchoServerHandler()); } }).option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture f = b.bind(port).sync(); //开始监听 f.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws InterruptedException { //启动echo服务端 new EchoServer(8080).run(); }} 12345678910public class EchoServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //读事件触发后回调该方法，读写数据 ByteBuf buf = (ByteBuf) msg; ctx.write(buf.readBytes(buf.readableBytes())); ctx.flush(); }} 客户端1234567891011121314151617181920212223242526272829303132333435363738394041424344public class EchoClient { public static void main(String[] args) { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); //监听connect、read、write事件的eventloop try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) //TCP NIO模式 .handler(new ChannelInitializer&lt;SocketChannel&gt;() { //注册处理器 @Override protected void initChannel(SocketChannel ch) throws Exception { //将hander添加到pipeline中，eventloop监听到事件后，依次回调pipeline上的每个handler ch.pipeline().addLast(new ChannelInboundHandlerAdapter() { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //TCP连接上后，回调该方法发送数据 ByteBuf buf = ctx.alloc().buffer(); buf.writeCharSequence(&quot;hello world&quot;, Charset.forName(&quot;UTF-8&quot;)); ctx.writeAndFlush(buf).addListener(future -&gt; { //发送完成后回调该方法 System.out.println(&quot;write future: &quot; + future.isSuccess()); }); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //读事件触发后回调该方法，读取服务端响应数据，并断开TCP链接 ByteBuf buf = (ByteBuf) msg; System.out.println(buf.readCharSequence(buf.readableBytes(), Charset.forName(&quot;UTF-8&quot;))); ReferenceCountUtil.release(buf); ctx.close().addListener(future -&gt; { System.out.println(&quot;echo client close: &quot; + future.isSuccess()); }); } }); } }); ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 8080).sync(); //连接服务端 future.channel().closeFuture().sync(); //阻塞等待TCP连接关闭 } catch (InterruptedException e) { eventLoopGroup.shutdownGracefully(); } }} Netty线程模型 通过讲解Netty的线程模型，我们简单理解下上面的demo程序做了什么 服务端线程模型 我们引用了这张都已经模糊了的网图，借此讲一下我们刚刚启动的echo服务端的线程模型。 首先我们忽略图上所谓reactor的概念，echo服务端主要包含两个线程池，分别对应图上的Reactor Thread Acceptor(Acceptor)和Reactor Thread Pool(Worker) 上面代码中的bossGroup我们称它为Acceptor线程池，我们通过构造函数指定了它只包含一个线程，它负责监听客户端连接事件，连接事件触发后，它从worker线程池选择一个worker线程，并将客户端连接绑定到这个线程上； workerGroup我们称它为worker线程池，不传参数的情况下，netty根据Cpu核数指定一个最优的线程数。这些线程负责监听绑定在他们身上的客户端连接的读写事件，并触发pipeline上的handler 客户端线程模型 和服务端不同，echo的客户端只有一个线程，这个线程在处理连接的同时，还要处理读写事件 Netty六大实体 这一节，我们先大概讲一下Netty中有哪些实体，他们分别做了什么事情，这有利于后面我们解读Netty的源码 Bootstrap：启动器，类似建造者模式，用于配置netty，方便我们快速启动netty应用 EventLoop：事件轮询器，一个EventLoop对应一个线程，主要负责轮询IO事件处理读写已经任务调度 EventLoopGroup：一组EventLoop Channel：类似java nio包的Channel，一个Channel对应一个客户端连接，Channel会绑定一个EventLoop ChannelPipeline：一个Channel会绑定一个ChannelPipeline，ChannelPipeline是一个类似过滤链的数据结构，存储了一组handler；当读写事件触发后，依序调用pipeline上的Handler ChannelInboundHandler：入站事件处理器 ChannelOutboundHandler：出站事件处理器 ByteBuf：类似java nio包的ByteBuffer，netty会维护一块堆外内存，对分配的对象进行池化，以此优化对象分配的耗时 ChannelHandlerContext：入站/出站事件的上下文，里面有很多有用的方法，开发Handler使用 ChannelFuture：类似java的Future，用于注册回调 深入Netty之前后面的章节我们将深入解析Netty的源码，我们的解析以Netty4为主（Netty5已被Netty官方废弃），文章中会穿插引用大量的Netty源码，这些源码都是经过筛选的，我们只讲最关键的部分，配合Netty源码食用更佳","link":"/2021/03/01/netty/2.netty/"},{"title":"2.锁机制","text":"表锁myisam和innodb都支持表级锁，其中myisam只支持表级锁，innodb优先使用行级锁，如果没有索引，则退化为表锁 行锁行锁是粒度最小的锁，性能较高，多个事务并发时有可能导致死锁 行锁从粒度上分： 记录锁 间隙锁 临键锁 共享锁共享锁也称为读锁，一个加了共享锁后，其他事务仍然可以加共享锁，但不能加排它锁 12select ... lock in share mode;----共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改 排它锁也称为写锁，加上排它锁后，不能再加其他锁 12select ... for update----排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁 意向共享锁和意向排它锁我们想象一种情况，事务A给表的某一行加上了行锁，事务B希望给表加表锁，如果申请成功，那么事务B可以修改表上的所有行，这有悖于行锁的设计 因此，加表锁首先需要检查是否有其他事务申请了表锁，然后再检查表上的所有行是否存在行锁。这效率实在是太低了 由此诞生了意向锁，意向锁也是一种表锁，若事务A需要申请行锁，那么他需要先加一个意向共享锁，事务B加表锁时，也需要申请意向锁，就被阻塞了 意向共享锁意味着有事务对行加了共享锁，意向排它锁意味着有事务对行加了排它锁 乐观锁乐观锁需要自己通过version实现，这是一种不需要加锁的机制 123456781. SELECT data AS old_data, version AS old_version FROM …;2. 根据获取的数据进行业务操作，得到new_data和new_version3. UPDATE SET data = new_data, version = new_version WHERE version = old_versionif (updated row &gt; 0) {// 乐观锁获取成功，操作完成} else {// 乐观锁获取失败，回滚并重试} 悲观锁悲观锁需要对数据加共享锁或排它锁 12345678910//1.开始事务begin; 或者 start transaction;//2.查询出商品信息，然后通过for update锁定数据防止其他事务修改select status from t_goods where id=1 for update;//3.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//4.修改商品status为2update t_goods set status=2;//4.提交事务commit; --执行完毕，提交事务 记录锁行级锁记录，没什么好讲的 间隙锁若一条数据不存在，事务隔离级别是可重复读，那么读取不重复的记录就会加间隙锁 假设有以下数据：(-∞,1),(1,5),(5,8),(8,10),(10,20),(20,+∞) 对7加锁，就会加上(5，8)的间隙锁 临键锁假设有以下数据：(-∞,1),(1,5),(5,8),(8,10),(10,20),(20,+∞) 事务A加的锁跨越了(1,5)和(5,8)两个间隙 死锁123SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;--查看正在被锁的事务kill trx_mysql_thread_id；--（上图trx_mysql_thread_id列的值）","link":"/2021/04/21/mysql/2.lock/"},{"title":"3. Bootstrap源码分析","text":"BootstrapBootstrap是netty提供给客户端与服务端建立连接的引导类，帮助我们快速启动一个Netty应用，接下来我们以EchoServer为例，看看Bootstrap是如何启动一个Netty服务端的 12345678910111213141516171819202122232425262728293031323334353637public class EchoServer { private int port; public EchoServer(int port) { this.port = port; } public void run() throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); //监听accept事件的eventloop EventLoopGroup workerGroup = new NioEventLoopGroup(); //监听read、write等事件的eventloop try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) //注册eventloop .channel(NioServerSocketChannel.class) //TCP NIO模式 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { //将EchoServerHandler这个hander添加到pipeline中，eventloop监听到事件后，依次回调pipeline上的每个handler ch.pipeline().addLast(new EchoServerHandler()); } }).option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture f = b.bind(port).sync(); //开始监听 f.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws InterruptedException { //启动echo服务端 new EchoServer(8080).run(); }} 源码分析Bootstrap使用了建造者模式，我们看看设置channel、eventLoop、handler、option时，Bootstrap做了什么；再看看Bootstrap如何启动服务器 构造函数123456public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { public ServerBootstrap() { //空构造函数 }} 设置EventLoop12345678910111213141516public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { //设置acceptor super.group(parentGroup); if (childGroup == null) { throw new NullPointerException(&quot;childGroup&quot;); } if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } //设置worker this.childGroup = childGroup; return this; }} 12345678910111213public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { public B group(EventLoopGroup group) { if (group == null) { throw new NullPointerException(&quot;group&quot;); } if (this.group != null) { throw new IllegalStateException(&quot;group set already&quot;); } this.group = group; return self(); }} 设置Channel设置Channel的本质是设置了一个ReflectiveChannelFactory，这是一个工厂模式的实现，运行时，这个工厂以反射的形式新建Channel 123456789101112131415161718192021222324252627282930public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } //设置channel工厂 return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass)); } public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) { return channelFactory((ChannelFactory&lt;C&gt;) channelFactory); } public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) { if (channelFactory == null) { throw new NullPointerException(&quot;channelFactory&quot;); } if (this.channelFactory != null) { throw new IllegalStateException(&quot;channelFactory set already&quot;); } this.channelFactory = channelFactory; return self(); } private B self() { return (B) this; }} 1234567891011121314151617181920212223242526272829public class ReflectiveChannelFactory&lt;T extends Channel&gt; implements ChannelFactory&lt;T&gt; { private final Constructor&lt;? extends T&gt; constructor; public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) { ObjectUtil.checkNotNull(clazz, &quot;clazz&quot;); try { this.constructor = clazz.getConstructor(); } catch (NoSuchMethodException e) { throw new IllegalArgumentException(&quot;Class &quot; + StringUtil.simpleClassName(clazz) + &quot; does not have a public non-arg constructor&quot;, e); } } @Override public T newChannel() { try { return constructor.newInstance(); } catch (Throwable t) { throw new ChannelException(&quot;Unable to create Channel from class &quot; + constructor.getDeclaringClass(), t); } } @Override public String toString() { return StringUtil.simpleClassName(ReflectiveChannelFactory.class) + '(' + StringUtil.simpleClassName(constructor.getDeclaringClass()) + &quot;.class)&quot;; }} 设置Handler1234567891011public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { public ServerBootstrap childHandler(ChannelHandler childHandler) { if (childHandler == null) { throw new NullPointerException(&quot;childHandler&quot;); } //设置worker的handler this.childHandler = childHandler; return this; }} 设置Option类似childXXX的方法设置的都是worker的属性，我们注意到ServerBootstrap继承了AbstractBootstrap，而类似childXXX的方法都在ServerBootstrap中，这是因为只有服务端会分两组EventLoop，分别服务连接客户端和处理读写事件。设置worker的方法都在子类里，而设置自己的方法则在父类中，从而达到复用的目的。如果我们启动的是客户端程序，使用的是Bootstrap类，这个类也继承了AbstractBootstrap，而且大部分的方法都在父类中 123456789101112131415161718public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { public &lt;T&gt; B option(ChannelOption&lt;T&gt; option, T value) { if (option == null) { throw new NullPointerException(&quot;option&quot;); } if (value == null) { synchronized (options) { options.remove(option); } } else { synchronized (options) { options.put(option, value); } } return self(); }} 开始监听12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { public ChannelFuture bind(int inetPort) { return bind(new InetSocketAddress(inetPort)); } public ChannelFuture bind(SocketAddress localAddress) { //校验了一下，具体就不看了 validate(); if (localAddress == null) { throw new NullPointerException(&quot;localAddress&quot;); } return doBind(localAddress); } private ChannelFuture doBind(final SocketAddress localAddress) { //initAndRegister是最关键的一步，返回了Future，说明这一步可能是异步的 final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { //有异常 return regFuture; } if (regFuture.isDone()) { //initAndRegister已经完成，执行doBind0 ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { //initAndRegister未完成，设置回调，待完成后执行doBind0 final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { promise.setFailure(cause); } else { promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } }} 关键的initAndRegister和doBind0我们分开看，我们先看initAndRegister，再倒回来看doBind0 1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { final ChannelFuture initAndRegister() { Channel channel = null; try { //Channel工厂新建了Channel channel = channelFactory.newChannel(); //执行init init(channel); } catch (Throwable t) { if (channel != null) { channel.unsafe().closeForcibly(); return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); } //执行register，register可能是异步的 ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } return regFuture; } /** * 这是一个抽象方法！！说明服务端和客户端的实现不一样！！ */ abstract void init(Channel channel) throws Exception;} 这里我们只看ServerBootstrap的init方法，EchoServer全部看完后，我们再看Bootstrap的init 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { @Override void init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); } //设置了ChannelInitializer，register的时候会初始化ChannelPipeline，最终调用的就是这个方法，后面我们还会讲这个方法 p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { //ServerBootstrapAcceptor是acceptor连接客户端的关键，后面分析连接客户端源码时我们再看它 pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); }} 由此看出，init方法名副其实，就是在初始化Channel，包括初始化option、attr、pipeline等；接下来看看register，我们发现register是属于EventLoopGroup的方法，是的，他做的就是将channel绑定到EventLoopGroup上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public abstract class MultithreadEventLoopGroup extends MultithreadEventExecutorGroup implements EventLoopGroup { @Override public ChannelFuture register(Channel channel) { return next().register(channel); } @Override public EventLoop next() { //根据不同的EventLoopGroup的实现，已不同的策略选择一个EventLoop，最终将Channel绑定到这个EventLoop上 return (EventLoop) super.next(); }}public abstract class MultithreadEventExecutorGroup extends AbstractEventExecutorGroup { private final EventExecutorChooserFactory.EventExecutorChooser chooser; @Override public EventExecutor next() { //具体实现在chooser中，有GenericEventExecutorChooser和PowerOfTwoEventExecutorChooser两种chooser，都是为了负载均衡，不讲这么细了，代码比较简单，感兴趣的可以自己看一看 return chooser.next(); }}public abstract class SingleThreadEventLoop extends SingleThreadEventExecutor implements EventLoop { @Override public ChannelFuture register(Channel channel) { return register(new DefaultChannelPromise(channel, this)); } @Override public ChannelFuture register(final ChannelPromise promise) { ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); return promise; }}public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { protected abstract class AbstractUnsafe implements Unsafe { @Override public final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(&quot;eventLoop&quot;); } if (isRegistered()) { promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); return; } if (!isCompatible(eventLoop)) { promise.setFailure( new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); return; } //这是一个双向绑定，Channel也会绑定EventLoop AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { //真正的register；我们注意到以0结尾的都是最终真正执行的方法 register0(promise); } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } } } private void register0(ChannelPromise promise) { try { if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; //doXXX也是真正执行的方法 doRegister(); neverRegistered = false; registered = true; //初始化pipeline，以此执行ChannelHandler的handlerAdded，这是ChannelInitializer的一个关键方法，在Channel初始化时执行 pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); //在pipeline中传递register完成这个事件；注意：fireChannelXXX指的是传递一个已完成的事件 //pipeline的fireChannelXXX方法的行为都类似的，后面我们就不看了，直接看对应ChannelHandler上的方法 pipeline.fireChannelRegistered(); if (isActive()) { //channel已经active才会走到这里，目前调试的都不会走到这一段，搞不懂什么时候会走到 if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { beginRead(); } } } catch (Throwable t) { closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } } }} 接下来我们依序分析doRegister、invokeHandlerAddedIfNeeded和fireChannelRegistered，先看doRegister 12345678910111213141516171819202122232425262728293031public abstract class AbstractNioChannel extends AbstractChannel { /** * Netty Channel和java Channel一一对应 */ private final SelectableChannel ch; @Override protected void doRegister() throws Exception { boolean selected = false; for (;;) { try { //这是jdk提供的nio接口，将channel注册到selector上 //同时我们发现selector绑定在了EventLoop上，这是因为EventLoop需要负责多个Channel，Selector可以帮助Channel同时监听多个Channel上的读写事件 selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { eventLoop().selectNow(); selected = true; } else { throw e; } } } } protected SelectableChannel javaChannel() { return ch; }} invokeHandlerAddedIfNeeded会执行ChannelPipeline上每个ChannelHandler的handlerAdded方法，这是handler add到pipeline上的一个回调事件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137public class DefaultChannelPipeline implements ChannelPipeline { private PendingHandlerCallback pendingHandlerCallbackHead; final void invokeHandlerAddedIfNeeded() { assert channel.eventLoop().inEventLoop(); if (firstRegistration) { firstRegistration = false; callHandlerAddedForAllHandlers(); } } private void callHandlerAddedForAllHandlers() { final PendingHandlerCallback pendingHandlerCallbackHead; synchronized (this) { assert !registered; registered = true; pendingHandlerCallbackHead = this.pendingHandlerCallbackHead; this.pendingHandlerCallbackHead = null; } //执行任务 PendingHandlerCallback task = pendingHandlerCallbackHead; while (task != null) { task.execute(); task = task.next; } } private final class PendingHandlerAddedTask extends PendingHandlerCallback { PendingHandlerAddedTask(AbstractChannelHandlerContext ctx) { super(ctx); } @Override public void run() { callHandlerAdded0(ctx); } @Override void execute() { EventExecutor executor = ctx.executor(); if (executor.inEventLoop()) { //最终执行callHandlerAdded0 callHandlerAdded0(ctx); } else { try { executor.execute(this); } catch (RejectedExecutionException e) { if (logger.isWarnEnabled()) { logger.warn( &quot;Can't invoke handlerAdded() as the EventExecutor {} rejected it, removing handler {}.&quot;, executor, ctx.name(), e); } remove0(ctx); ctx.setRemoved(); } } } } private void callHandlerAdded0(final AbstractChannelHandlerContext ctx) { try { ctx.callHandlerAdded(); } catch (Throwable t) { boolean removed = false; try { remove0(ctx); ctx.callHandlerRemoved(); removed = true; } catch (Throwable t2) { if (logger.isWarnEnabled()) { logger.warn(&quot;Failed to remove a handler: &quot; + ctx.name(), t2); } } if (removed) { fireExceptionCaught(new ChannelPipelineException( ctx.handler().getClass().getName() + &quot;.handlerAdded() has thrown an exception; removed.&quot;, t)); } else { fireExceptionCaught(new ChannelPipelineException( ctx.handler().getClass().getName() + &quot;.handlerAdded() has thrown an exception; also failed to remove.&quot;, t)); } } }}abstract class AbstractChannelHandlerContext extends DefaultAttributeMap implements ChannelHandlerContext, ResourceLeakHint { final void callHandlerAdded() throws Exception { if (setAddComplete()) { //每个handler都绑定在一个HandlerContext上，通过HandlerContext代理执行handler的方法 //在init的时候，ServerBootstrap添加了一个ChannelInitializer，这里执行的就是ChannelInitializer的handlerAdded handler().handlerAdded(this); } } }public abstract class ChannelInitializer&lt;C extends Channel&gt; extends ChannelInboundHandlerAdapter { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { if (ctx.channel().isRegistered()) { if (initChannel(ctx)) { removeState(ctx); } } } private boolean initChannel(ChannelHandlerContext ctx) throws Exception { if (initMap.add(ctx)) { try { //执行init，这个init就是ServerBootstrap在init的时候添加的，这个初始化器做的就是将ServerBootstrapAcceptor添加到pipeline中 initChannel((C) ctx.channel()); } catch (Throwable cause) { exceptionCaught(ctx, cause); } finally { //ChannelInitializer在初始化完成后，会把自己从pipeline上移除 ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { pipeline.remove(this); } } return true; } return false; }} initAndRegister就讲完了，init主要做的就是初始化Channel，包括初始化option、attr、pipeline等；而register是做了Channel和EventLoop的双向绑定，将channel注册到selector上，并初始化Pipeline，将ServerBootstrapAcceptor加到pipeline中 接下来我们看bind 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { public ChannelFuture bind() { validate(); SocketAddress localAddress = this.localAddress; if (localAddress == null) { throw new IllegalStateException(&quot;localAddress not set&quot;); } return doBind(localAddress); } private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { //最终执行的是doBind0 ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { promise.setFailure(cause); } else { promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } } private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { //在channel对应的eventLoop上执行bind channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); }}public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { @Override public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { //pipeline的connect和bind是两个比较特别的方法，最终调用的是pipeline对应的Channel return pipeline.bind(localAddress, promise); }}public class DefaultChannelPipeline implements ChannelPipeline { @Override public final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return tail.bind(localAddress, promise); }}abstract class AbstractChannelHandlerContext extends DefaultAttributeMap implements ChannelHandlerContext, ResourceLeakHint { @Override public ChannelFuture bind(final SocketAddress localAddress, final ChannelPromise promise) { if (localAddress == null) { throw new NullPointerException(&quot;localAddress&quot;); } if (isNotValidPromise(promise, false)) { // cancelled return promise; } final AbstractChannelHandlerContext next = findContextOutbound(); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeBind(localAddress, promise); } else { safeExecute(executor, new Runnable() { @Override public void run() { next.invokeBind(localAddress, promise); } }, promise, null); } return promise; } private void invokeBind(SocketAddress localAddress, ChannelPromise promise) { if (invokeHandler()) { try { //最后调用到handler的bind ((ChannelOutboundHandler) handler()).bind(this, localAddress, promise); } catch (Throwable t) { notifyOutboundHandlerException(t, promise); } } else { bind(localAddress, promise); } }}public class DefaultChannelPipeline implements ChannelPipeline { final class HeadContext extends AbstractChannelHandlerContext implements ChannelOutboundHandler, ChannelInboundHandler { @Override public void bind( ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) { unsafe.bind(localAddress, promise); } }}public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { protected abstract class AbstractUnsafe implements Unsafe { @Override public final void bind(final SocketAddress localAddress, final ChannelPromise promise) { assertEventLoop(); if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } if (Boolean.TRUE.equals(config().getOption(ChannelOption.SO_BROADCAST)) &amp;&amp; localAddress instanceof InetSocketAddress &amp;&amp; !((InetSocketAddress) localAddress).getAddress().isAnyLocalAddress() &amp;&amp; !PlatformDependent.isWindows() &amp;&amp; !PlatformDependent.maybeSuperUser()) { logger.warn( &quot;A non-root user can't receive a broadcast packet if the socket &quot; + &quot;is not bound to a wildcard address; binding to a non-wildcard &quot; + &quot;address (&quot; + localAddress + &quot;) anyway as requested.&quot;); } boolean wasActive = isActive(); try { //设置监听 doBind(localAddress); } catch (Throwable t) { safeSetFailure(promise, t); closeIfClosed(); return; } if (!wasActive &amp;&amp; isActive()) { invokeLater(new Runnable() { @Override public void run() { //回调Channel Active事件 pipeline.fireChannelActive(); } }); } safeSetSuccess(promise); } } /** * 这是一个抽象方法，不同的Channel bind实现不一样 */ protected abstract void doBind(SocketAddress localAddress) throws Exception;}public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel { @Override protected void doBind(SocketAddress localAddress) throws Exception { //调用到jdk的bind，开始端口监听 if (PlatformDependent.javaVersion() &gt;= 7) { javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); } } } 接下来我们分别看doBind和pipeline.fireChannelActive() 123456789101112131415161718192021public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { /** * 这是一个抽象方法，不同的Channel bind实现不一样 */ protected abstract void doBind(SocketAddress localAddress) throws Exception;}public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel { @Override protected void doBind(SocketAddress localAddress) throws Exception { //调用到jdk的bind，开始端口监听 if (PlatformDependent.javaVersion() &gt;= 7) { javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); } } } doBind就是设置了端口监听，pipeline.fireChannelActive()之前我们讲过，类似这种方法，就是回调Channel Active的事件，我们看看回调事件时，pipeline还干了什么（这里会跳过Pipeline和AbstractChannelHandlerContext中大量类似的代码） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class DefaultChannelPipeline implements ChannelPipeline { @Override public final ChannelPipeline fireChannelActive() { AbstractChannelHandlerContext.invokeChannelActive(head); return this; } final class HeadContext extends AbstractChannelHandlerContext implements ChannelOutboundHandler, ChannelInboundHandler { @Override public void channelActive(ChannelHandlerContext ctx) { ctx.fireChannelActive(); //active后自动设置读监听 readIfIsAutoRead(); } private void readIfIsAutoRead() { if (channel.config().isAutoRead()) { channel.read(); } } }}public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { @Override public Channel read() { //从tail往head调read，最终调用的是HeadContext的read pipeline.read(); return this; }}public class DefaultChannelPipeline implements ChannelPipeline { final class HeadContext extends AbstractChannelHandlerContext implements ChannelOutboundHandler, ChannelInboundHandler { @Override public void read(ChannelHandlerContext ctx) { unsafe.beginRead(); } }}public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { protected abstract class AbstractUnsafe implements Unsafe { @Override public final void beginRead() { assertEventLoop(); if (!isActive()) { return; } try { doBeginRead(); } catch (final Exception e) { invokeLater(new Runnable() { @Override public void run() { pipeline.fireExceptionCaught(e); } }); close(voidPromise()); } } } /** * 这是一个抽象方法，不同Channel实现不同 */ protected abstract void doBeginRead() throws Exception;}public abstract class AbstractNioChannel extends AbstractChannel { @Override protected void doBeginRead() throws Exception { final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) { //开始监听读事件 selectionKey.interestOps(interestOps | readInterestOp); } }} 到这里，EchoServer的启动就分析完了，我们来总结一下整个启动流程中最关键的initAndRegister和doBind0 initAndRegister 新建Channel init：设置Option、Attr，并为Pipeline设置ChannelInitializer register：EventLoop和Channel双向绑定，把Channel上的jdk Channel注册到EventLoop的Selector上，最后初始化pipeline，把ServerBootstrapAcceptor绑定到pipeline上 doBind0： doBind：开始端口监听 pipeline.fireChannelActive()：channel active后，若开启autoRead，则自动设置读监听 附上时序图： 未完待续","link":"/2021/03/03/netty/3.bootstrap/"},{"title":"1.索引与存储引擎","text":"B+树Mysql使用B+树作为索引，采用B+树有以下优势： B+树属于多路查找树，每个索引节点的子节点数量较多，查找性能高 B+树节点存储大小适配操作系统页面大小，那么读取数据只需要一次IO，性能高 相对B树，B+树只在叶子节点存储数据，索引节点上只存储Key，可存储叶子节点数更多 一般Mysql的B+树索引只有三层，可存储2000w条数据；千万级别的表，只需要2次IO，三次查找即可。数据大于2000w后，可能导致性能急剧下降 我们可以看出，B+树有两大特点，因此索引可用于快速查找和排序 多路查找 叶子节点有序 需要注意以下几点： 若索引字段区分度低，那么索引的效果会很差 索引数量越多，索引的B+树越多，数据插入越慢 优化器会根据索引查询的代价计算是否使用索引，比如过多的in会导致全表扫描 对索引字段进行表达式查询、like查询等不走索引 mysql也有hash类型的索引，但是hash类型的索引容易出现hash冲突，而且不能做范围查询，从存储IO的角度上看并不适合数据库，一般不使用 主键索引与非主键索引 主键索引是使用主键作为Key的索引，叶子节点存储指向数据的指针 非主键索引是使用非主键作为Key的索引，叶子节点存储记录的主键，然后再到主键索引上进行查找，这称为回表，这能有效减少存储 联合索引采用联合索引时，B+树的Key是联合索引的第一个字段，联合索引的其他字段会用于叶子节点的排序 联合索引采用最左匹配原则，优先通过前面的字段进行查找 并不是所有使用非主键索引进行的查询都需要回表，若联合索引中存在查询需要的字段，则不会触发回表，这称为覆盖索引 Mysql5.7做了一个优化，使用联合索引进行查询，前面的字段可用索引，后面的字段在联合索引中，采用like查询，不会直接进行回表，而是先进行like过滤再进行回表操作，这称为索引下推 排序不一定会用上联合索引，例如排序的字段并非B+树的Key，而且通过Key定位到了多个值，由联合索引结构可知，在相同值下，联合索引的字段是有序的，排序可以直接使用。若跨多个值，则需要重新排序 存储引擎myisam引擎是5.1版本之前的默认引擎，支持全文检索、压缩、空间函数等，但是不支持事务和行级锁（只支持表级），所以一般用于有大量查询少量插入的场景来使用，而且myisam不支持外键，并且索引和数据是分开存储的 innodb是基于聚簇索引建立的，支持主键自增，和myisam相反它支持事务、外键、行级锁，并且通过MVCC来支持高并发，索引和数据存储在一起","link":"/2021/04/21/mysql/1.index/"},{"title":"4.事务机制","text":"事务我们可以通过 set session autoCommit = on/off 来设置mysql事务是否自动开启 如果我们设置autoCommit为off的时候，我们需要手动开启mysql事务 begin；start transaction；—-开启事务（2选1） 通过 commit；或者 rollback；设置事务提交或者回滚 事务有四大特性（ACID）： 原子性：数据流动，A-B+ 一致性：保证每次事务结束后的状态一致 隔离性：事务间隔离 持久性：事务提交后永久生效 四大隔离级别 读未提交：A事务可以读到B事务未提交的数据 读已提交：A事务只能读其他事务已提交的数据。这是大多数据库的默认隔离级别，会导致脏读（两次查询结果不一样） 可重复读：解决了脏读的问题，但可能导致幻读（个人认为，幻读指的是查询时只有一条记录，却更新了不止一条记录） 串行：加锁 MVCC binlog：事务提交后的日志，可用于主从复制 redolog：未提交的日志，可用于数据恢复 undolog：回滚的日志，可用于事务回滚 MVCC 全称是多版本并发控制系统，用于解决事务并发时锁开销的问题。InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现，这两个列一个保存了行的创建的事务版本号，一个保存行的删除的事务版本号。每开始一个新的事务，事务版本号都会自动递增，作为事务的版本号。下面是他的核心原理（实际上是通过一种叫ReadView的机制去做的，记录的是事务号和undolog，详细机制以后有机会看mysql源码的时候再研究吧） 新建时，将事务版本号写入创建的版本号 删除时，新建一条数据，将事务的版本号写入老数据的删除版本号 查询时，只能查到创建的版本号小于等于事务版本号的记录 且 删除版本号为空 或 删除版本号大于当前事务版本号的记录","link":"/2021/04/21/mysql/3.transaction/"},{"title":"1.TCP协议","text":"TCP协议 首先，对于传输层协议，端口号是必不可少的，否则不知道包发给哪个进程； 接下来是序列号，TCP通过序列号和确认机制保证包的顺序和到达 接下来有一些状态位，例如SYN建立连接，ACK确认，RST是重连，FIN是关闭连接 还有一个重要的是窗口，TCP通过窗口大小进行流量控制和拥塞控制 三次握手 四次挥手 服务端大量close_wait：连接未关闭导致 RST状态转换 序列号、确认与重传机制为了保证包的顺序性，TCP的每个包都有序列号，接收方通过ACK机制表示某个序列号以前的包都收到了，这叫做累计确认 对发送方而言，包是有序的，分为4个部分：接收方已确认的包、已发送但未确认的包、窗口内可以发送但未发送的包、不可发送的包 对接收方而言，包也是有序的，分为3个部分：已确认的包、未确认的包、不可接收的包 窗口由接收方在ACK中给出，可用于流量控制 网络环境再好，也有可能丢包，针对丢失的包，TCP有重传机制 超时重传：TCP通过自适应重传算法，统计回包时间并估算超时时间，超时即认为丢包，并进行重发 SACK重传：TCP通过SACK机制确认了6、8、9包，就说明7丢包了，需要重传 快速重传：TCP通过确认重复的序列号，表示出现了丢包，需要立即重传 流量控制TCP由内核实现，接收方收到包后，内核会将收到的包缓存起来，再由应用程序读取。若应用程序一直未读取数据，缓存的数据就会很多。TCP为了保护自己，有了流量控制机制 通过再ACK中携带接收方的窗口大小，知道发送方可发送包的范围，从而达到流量控制的目的。若接收方应用程序一直不读取数据，随着接收方确认的包数量增长，窗口大小最终会缩小为0，发送方则停止发送数据。之后发送方会进行窗口探测，知道窗口恢复 拥塞控制网络的带宽是有限的，若发包速度过快，就有可能导致网络拥塞，出现大量丢包，因此，TCP需要有控制发送速率的机制 因此有了慢启动算法，TCP通过滑动窗口和拥塞窗口控制发包速率，滑动窗口就是接收方的窗口，用于进行流量控制。而拥塞窗口则用于拥塞控制 从TCP连接开始，拥塞窗口cwnd只有一个报文的大小，当收到一个ACK时，拥塞窗口大小+1，这是指数的增长。 当达到sshresh阈值时，窗口增长会变慢，变为1/cwnd的大小，变为线性增长 当出现拥塞重传时，sshresh会变为cwnd/2的大小，而拥塞窗口则变为1或cwnd/2，重新开始慢启动","link":"/2021/04/16/network/1.tcp/"},{"title":"2.HTTP协议","text":"","link":"/2021/04/16/network/2.http/"},{"title":"1. Zuul网关","text":"Zuul网关 Zuul2 QuickStart Zuul2服务启动 从ChannelHandler到FilterRunner Filter热加载 Filter异步化 流式转发 响应式 负载均衡与服务发现","link":"/2021/03/05/zuul/1.zuul/"},{"title":"1.进程管理","text":"进程进程是资源（CPU、内存等）分配的基本单位，具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。 进程间存在父子关系，以树状形式存在 通过ps-ef命令，我们能看到当前系统启动的进程。PID表示的是进程id，PPID表示的是父进程的id。带中括号的内核态的进程，祖先都是 2 号进程。而用户态的进程，祖先都是 1 号进程。tty 那一列，是问号的，说明不是前台启动的，一般都是后台的服务 1234567891011121314151617181920212223[root@deployer ~]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 2018 ? 00:00:29 /usr/lib/systemd/systemd --system --deserialize 21root 2 0 0 2018 ? 00:00:00 [kthreadd]root 3 2 0 2018 ? 00:00:00 [ksoftirqd/0]root 5 2 0 2018 ? 00:00:00 [kworker/0:0H]root 9 2 0 2018 ? 00:00:40 [rcu_sched]......root 337 2 0 2018 ? 00:00:01 [kworker/3:1H]root 380 1 0 2018 ? 00:00:00 /usr/lib/systemd/systemd-udevdroot 415 1 0 2018 ? 00:00:01 /sbin/auditdroot 498 1 0 2018 ? 00:00:03 /usr/lib/systemd/systemd-logind......root 852 1 0 2018 ? 00:06:25 /usr/sbin/rsyslogd -nroot 2580 1 0 2018 ? 00:00:00 /usr/sbin/sshd -Droot 29058 2 0 Jan03 ? 00:00:01 [kworker/1:2]root 29672 2 0 Jan04 ? 00:00:09 [kworker/2:1]root 30467 1 0 Jan06 ? 00:00:00 /usr/sbin/crond -nroot 31574 2 0 Jan08 ? 00:00:01 [kworker/u128:2]......root 32792 2580 0 Jan10 ? 00:00:00 sshd: root@pts/0root 32794 32792 0 Jan10 pts/0 00:00:00 -bashroot 32901 32794 0 00:01 pts/0 00:00:00 ps -ef 系统调用创建进程12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt; extern int create_process (char* program, char** arg_list); int create_process (char* program, char** arg_list){ pid_t child_pid; child_pid = fork (); if (child_pid != 0) return child_pid; else { execvp (program, arg_list); abort (); }}#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;extern int create_process (char* program, char** arg_list);int main (){ char* arg_list[] = { &quot;ls&quot;, &quot;-l&quot;, &quot;/etc/yum.repos.d/&quot;, NULL }; create_process (&quot;ls&quot;, arg_list); return 0;} 系统调用创建线程进程是资源分配的最小单位，线程是CPU调度的最小单位。线程共享进程的内存、文件等资源，开销较小 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NUM_OF_TASKS 5void *downloadfile(void *filename){ printf(&quot;I am downloading the file %s!\\n&quot;, (char *)filename); sleep(10); long downloadtime = rand()%100; printf(&quot;I finish downloading the file within %d minutes!\\n&quot;, downloadtime); pthread_exit((void *)downloadtime);}int main(int argc, char *argv[]){ char files[NUM_OF_TASKS][20]={&quot;file1.avi&quot;,&quot;file2.rmvb&quot;,&quot;file3.mp4&quot;,&quot;file4.wmv&quot;,&quot;file5.flv&quot;}; pthread_t threads[NUM_OF_TASKS]; int rc; int t; int downloadtime; pthread_attr_t thread_attr; pthread_attr_init(&amp;thread_attr); pthread_attr_setdetachstate(&amp;thread_attr,PTHREAD_CREATE_JOINABLE); for(t=0;t&lt;NUM_OF_TASKS;t++){ printf(&quot;creating thread %d, please help me to download %s\\n&quot;, t, files[t]); rc = pthread_create(&amp;threads[t], &amp;thread_attr, downloadfile, (void *)files[t]); if (rc){ printf(&quot;ERROR; return code from pthread_create() is %d\\n&quot;, rc); exit(-1); } } pthread_attr_destroy(&amp;thread_attr); for(t=0;t&lt;NUM_OF_TASKS;t++){ pthread_join(threads[t],(void**)&amp;downloadtime); printf(&quot;Thread %d downloads the file %s in %d minutes.\\n&quot;,t,files[t],downloadtime); } pthread_exit(NULL);} 线程的数据分为以下三类： 线程栈上的本地数据（例如线程中声明的局部变量） 在整个进程里共享的全局数据（堆上的数据） 线程私有数据（通过pthread_setspecific设置的数据） 线程通过互斥量（Mutex）保护线程间数据读写的同步 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NUM_OF_TASKS 5int money_of_tom = 100;int money_of_jerry = 100;//第一次运行去掉下面这行pthread_mutex_t g_money_lock;void *transfer(void *notused){ pthread_t tid = pthread_self(); printf(&quot;Thread %u is transfering money!\\n&quot;, (unsigned int)tid); //第一次运行去掉下面这行 pthread_mutex_lock(&amp;g_money_lock); sleep(rand()%10); money_of_tom+=10; sleep(rand()%10); money_of_jerry-=10; //第一次运行去掉下面这行 pthread_mutex_unlock(&amp;g_money_lock); printf(&quot;Thread %u finish transfering money!\\n&quot;, (unsigned int)tid); pthread_exit((void *)0);}int main(int argc, char *argv[]){ pthread_t threads[NUM_OF_TASKS]; int rc; int t; //第一次运行去掉下面这行 pthread_mutex_init(&amp;g_money_lock, NULL); for(t=0;t&lt;NUM_OF_TASKS;t++){ rc = pthread_create(&amp;threads[t], NULL, transfer, NULL); if (rc){ printf(&quot;ERROR; return code from pthread_create() is %d\\n&quot;, rc); exit(-1); } } for(t=0;t&lt;100;t++){ //第一次运行去掉下面这行 pthread_mutex_lock(&amp;g_money_lock); printf(&quot;money_of_tom + money_of_jerry = %d\\n&quot;, money_of_tom + money_of_jerry); //第一次运行去掉下面这行 pthread_mutex_unlock(&amp;g_money_lock); } //第一次运行去掉下面这行 pthread_mutex_destroy(&amp;g_money_lock); pthread_exit(NULL);} 互斥量一般与条件变量一起使用，条件变量用于阻塞与唤醒（若数据没有到，不能一直持有锁并占用cpu） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NUM_OF_TASKS 3#define MAX_TASK_QUEUE 11char tasklist[MAX_TASK_QUEUE]=&quot;ABCDEFGHIJ&quot;;int head = 0;int tail = 0;int quit = 0;pthread_mutex_t g_task_lock;pthread_cond_t g_task_cv;void *coder(void *notused){ pthread_t tid = pthread_self(); while(!quit){ pthread_mutex_lock(&amp;g_task_lock); while(tail == head){ if(quit){ pthread_mutex_unlock(&amp;g_task_lock); pthread_exit((void *)0); } printf(&quot;No task now! Thread %u is waiting!\\n&quot;, (unsigned int)tid); pthread_cond_wait(&amp;g_task_cv, &amp;g_task_lock); printf(&quot;Have task now! Thread %u is grabing the task !\\n&quot;, (unsigned int)tid); } char task = tasklist[head++]; pthread_mutex_unlock(&amp;g_task_lock); printf(&quot;Thread %u has a task %c now!\\n&quot;, (unsigned int)tid, task); sleep(5); printf(&quot;Thread %u finish the task %c!\\n&quot;, (unsigned int)tid, task); } pthread_exit((void *)0);}int main(int argc, char *argv[]){ pthread_t threads[NUM_OF_TASKS]; int rc; int t; pthread_mutex_init(&amp;g_task_lock, NULL); pthread_cond_init(&amp;g_task_cv, NULL); for(t=0;t&lt;NUM_OF_TASKS;t++){ rc = pthread_create(&amp;threads[t], NULL, coder, NULL); if (rc){ printf(&quot;ERROR; return code from pthread_create() is %d\\n&quot;, rc); exit(-1); } } sleep(5); for(t=1;t&lt;=4;t++){ pthread_mutex_lock(&amp;g_task_lock); tail+=t; printf(&quot;I am Boss, I assigned %d tasks, I notify all coders!\\n&quot;, t); pthread_cond_broadcast(&amp;g_task_cv); pthread_mutex_unlock(&amp;g_task_lock); sleep(20); } pthread_mutex_lock(&amp;g_task_lock); quit = 1; pthread_cond_broadcast(&amp;g_task_cv); pthread_mutex_unlock(&amp;g_task_lock); pthread_mutex_destroy(&amp;g_task_lock); pthread_cond_destroy(&amp;g_task_cv); pthread_exit(NULL);} 操作系统如何管理进程Linux操作系统通过task_struct结构管理进程/线程，包括以下内容： 进程id、线程组id 信号处理相关 任务状态，只有处于TASK_RUNNING状态才可被调度 调度相关，如优先级、调度策略、调度器等 运行统计信息，如用户态/内核态消耗的cpu时间 进程间关系 进程权限 内存地址空间 打开的文件 用户态/内核态函数栈，通过栈可找到当前进程运行的地方，与进程调度密切相关 进程调度进程分为实时进程和普通进程，它们分别使用实时调度策略和普通调度策略，调度策略的优先级越高，调度的优先级就越高。对于相同的调度策略，进程优先级越高，调度的优先级就越高 实时调度策略分为以下几种： SCHED_FIFO：先进先出 SCHED_RR：轮换 SCHED_DEADLIN：deadline优先 普通调度策略有： SCHED_NORMAL：普通进程调度 SCHED_BATCH：低优先级的批处理任务的调度 SCHED_IDLE：空闲才调度 普通进程使用完全公平调度算法CFS进行调度，CFS为每个进程记录vruntime虚拟运行时间，vruntime由进程优先级和实际运行实际决定，实际运行实际越长，vruntime越大。优先级越高，vruntime越小。调度时，CFS取出vruntime最小的任务进行调度。 主动调度的本质就是通过进程主动调用schedule函数，让出cpu，例如进行IO操作时，数据未就绪，就会触发主动调度。此时，内核会选择下一个应该被调度的进程，并进行上下文切换（包括内存地址空间和栈的切换等），完成调度。 进程被唤醒或当前进程运行时间过长，就会发生抢占式调度，此时内核将当前进程标识为可被抢占，但不会进行切换。直到当前进程从系统调用返回或从中断返回时，才真正进行调度","link":"/2021/04/05/os/1.process/"},{"title":"2.内存管理","text":"虚拟内存空间为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情 内存分段在虚拟内存空间中，我们将栈、堆等分为不同的段，分别映射到物理内存，通过段表保存虚拟内存到物理内存的映射，寻址时根据虚拟内存地址（段起始地址和段内偏移量），即可找到对应的物理地址 分段机制存在一些问题，会导致内存碎片，小块的内存碎片上，无法分配连续内存给进程，导致浪费 内存分页Linux主要使用分页的机制。相对于分段，页的粒度更小，一般一个页只有4KB大小，一个进程的虚拟空间会有很多个页，这些页分别映射到物理内存的页上，根据页起始地址和页偏移量进行寻址，这有效的避免了内存分段带来的碎片问题，而且可以将不常用的页替换出到硬盘，要使用时再换入 对于一个32位的系统，虚拟内存空间最多能表示2^32个地址，也就是4GB。一个页4KB，那么就会有1M个页，每个页表项使用4个字节存储（32位用于表示物理地址），那一个进程就需要4MB的内存用于保存页表，100个进程就是400MB，这对内核来说实在是太大了 因此，有了多级页表的机制。我们想象一下，如果我们对4MB的页表再进行分页，每1K个页表归总为一个页目录项，一共1K个页目录项，每个页目录项用4个字节存储，那么只需要4KB就可以表示4GB的虚拟内存空间。当进程使用了4GB的内存时，页表加页表目录项共使用4MB+4KB的内存。但如果使用的内存远小于4GB，那么4MB的页表其实只需要加载一小部分 对于64位的系统，两级页表肯定是不够的，Linux中使用了4级的页表 内存布局进程的地址空间被分为用户态和内核态两个部分。用户态内存被分为栈、堆、mmap内存映射、数据、代码等多个部分部分。而内核态内存映射到的物理内存都是相同的，内核态内存分为代码、数据、内核栈、内核数据结构和内核动态分配的内存等 内存分配内存并不是连续的，首先分为节点和区域，区域下再是分页；这一块和计算机硬件相关我们不细讲，大概了解即可 内存分配主要分为两种 通过伙伴系统直接分配页，一般用于大内存的分配；这部分算法比较巧妙，内核维度了n个链表，分别表示2^n个连续页的起始地址，分配时，优先分配相近大小的连续页，若没有，则取更大的连续页，将其拆分为较小的连续页后再分配。举个例子，内核需要分配256个页，但256个页的链表已经空了，就找到512个页的链表，取到连续内存后，将其分为2个256的连续页，插入到256个页的链表中，再进行分配 通过Slub Allocator分配小对象。Slub Allocator会先通过伙伴系统分配大内存，然后通过对象池的方式，分配小对象 当内存紧张的时候，内核线程kswapd通过lru算法，将最不活跃的匿名页换出到文件系统，若是文件映射类型的页，kswapd会将脏页写回到文件（这就是虚拟内存，运用了局部性原理） 内存寻址多级页表解决了内存寻址和页表存储的问题。页表实际上存储在 CPU 的内存管理单元 （MMU），为了更快速地进行内存寻址，CPU中有TLB的硬件单元，专门用于存放最长使用的页表项 当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行 关于mmap一般read、write文件读写需要4次用户态和内核态的上下文切换和4次内存拷贝 用户进程通过read()方法向操作系统发起调用，此时上下文从用户态转向内核态 DMA控制器把数据从硬盘中拷贝到读缓冲区 CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态转为用户态，read()返回 用户进程通过write()方法发起调用，上下文从用户态转为内核态 CPU将应用缓冲区中数据拷贝到socket缓冲区 DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回 mmap将文件映射到内存，DMA控制器将数据拷贝到内存后，可直接映射到内核态，不需要拷贝 12345678910111213141516171819202122232425262728#include &lt;sys/mman.h&gt; /* for mmap and munmap */#include &lt;sys/types.h&gt; /* for open */#include &lt;sys/stat.h&gt; /* for open */#include &lt;fcntl.h&gt; /* for open */#include &lt;unistd.h&gt; /* for lseek and write */#include &lt;stdio.h&gt; int main(int argc, char **argv){ int fd; char *mapped_mem, * p; int flength = 1024; void * start_addr = 0; fd = open(argv[1], O_RDWR | O_CREAT, S_IRUSR | S_IWUSR); flength = lseek(fd, 1, SEEK_END); write(fd, &quot;\\0&quot;, 1); /* 在文件最后添加一个空字符，以便下面printf正常工作 */ lseek(fd, 0, SEEK_SET); mapped_mem = mmap(start_addr, flength, PROT_READ, //允许读 MAP_PRIVATE, //不允许其它进程访问此内存区域 fd, 0); /* 使用映射区域. */ printf(&quot;%s\\n&quot;, mapped_mem); /* 为了保证这里工作正常，参数传递的文件名最好是一个文本文件 */ close(fd); munmap(mapped_mem, flength); return 0;}","link":"/2021/04/06/os/2.memory/"},{"title":"3.文件系统","text":"命令行通过命令 fdisk -l，查看格式化和没有格式化的分区 12345678910111213141516171819# fdisk -lDisk /dev/vda: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000a4c75 Device Boot Start End Blocks Id System/dev/vda1 * 2048 41943006 20970479+ 83 LinuxDisk /dev/vdc: 107.4 GB, 107374182400 bytes, 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes 输出结果可以看出，vda 这块盘大小 21.5G，是格式化了的，有一个分区 /dev/vda1。vdc 这块盘大小 107.4G，是没有格式化的。我们可以通过命令 mkfs.ext3 或者 mkfs.ext4 进行格式化 1mkfs.ext4 /dev/vdc 你也可以选择不将整块盘格式化为一个分区，而是格式化为多个分区。下面的这个命令行可以启动一个交互式程序 1fdisk /dev/vdc 格式化后的硬盘，需要挂在到某个目录下面，才能作为普通的文件系统进行访问 12345//挂载mount /dev/vdc1 /根目录/用户A目录/目录1//卸载umount /根目录/用户A目录/目录1 Linux里面一切都是文件，通过ls -l查看文件类型 表示普通文件 d 表示文件夹 c 表示字符设备文件 b 表示块设备文件 s 表示套接字 socket 文件 l 表示符号链接，也即软链接，就是通过名字指向另外一个文件 系统调用Linux里面一切都是文件，通过文件描述符可以操作文件，包括设备、套接字等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int main(int argc, char *argv[]){ int fd = -1; int ret = 1; int buffer = 1024; int num = 0; if((fd=open(&quot;./test&quot;, O_RDWR|O_CREAT|O_TRUNC))==-1) { printf(&quot;Open Error\\n&quot;); exit(1); } ret = write(fd, &amp;buffer, sizeof(int)); if( ret &lt; 0) { printf(&quot;write Error\\n&quot;); exit(1); } printf(&quot;write %d byte(s)\\n&quot;,ret); lseek(fd, 0L, SEEK_SET); ret= read(fd, &amp;num, sizeof(int)); if(ret==-1) { printf(&quot;read Error\\n&quot;); exit(1); } printf(&quot;read %d byte(s)，the number is %d\\n&quot;, ret, num); close(fd); return 0;} 文件系统格式Linux下有众多文件系统，我们重点讲ext4文件系统 与内存分页类似，硬盘分成相同大小的单元，我们称为块。一般一个块4KB大小。这样一来，存储一个文件，不需要分配连续的硬盘空间，而是分配多个块。 inode维护了文件的元数据，包括文件名、文件权限、块的索引等。对于一个文件，我们需要持有多个块的索引，但inode的空间是有限的，inode通过i_block[12]的数组持有数据块的索引。类似多级页表，inode会持有间接块的索引，间接块上再存储数据块的索引 ext4文件系统通过inode位图和块位图描述inode和块是否被分配，位图中一个bit表示一个inode或一个块。位图占用4KB的存储空间，可以表示10^15个数据块，也就是10^27=128MB的硬盘空间。 采用inode+块+位图的的结构，最多只能表示128MB，这对硬盘来说还是太小了。ext4将这个结构表示为一个块组，整个文件系统被分为多个块组，通过超级块和块组描述符表描述一个块组的全局信息。 因为超级块和块组描述符表描述的是整个文件系统的全局信息，一旦损坏会影响整个文件系统，因此会进行备份。如果开启了 sparse_super 特性，超级块和块组描述符表的副本只会保存在块组索引为 0、3、5、7 的整数幂里 块组描述符表里面有多少项，这就限制了有多少个块组，因此又引入了元块组的概念。每个元块组都有自己的超级块和块组描述符表 目录存储格式其实目录本身也是个文件，也有 inode。inode 里面也是指向一些块。和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息 软连接、硬链接存储格式硬链接与原始文件共用一个 inode 的，但是 inode 是不跨文件系统的，每个文件系统都有自己的 inode 列表，因而硬链接是没有办法跨文件系统的。而软链接不同，软链接相当于重新创建了一个文件。这个文件也有独立的 inode，只不过打开这个文件看里面内容的时候，内容指向另外的一个文件 虚拟文件系统Linux通过虚拟文件系统屏蔽不同文件系统实现的差异","link":"/2021/04/06/os/3.file/"},{"title":"4.输入输出系统","text":"设备控制器输入输出设备分为块设备（例如硬盘）和字符设备（例如鼠标）两种，CPU通常不直接操作输入输出设备，而是通过设备控制器与输入输出设备进行交互，不同设备需要提供不同的设备控制器，如磁盘控制器、USB控制器等 需要操作设备时，CPU发送指令到设备控制器，设备控制器操作设备，将数据写入/读到内存，发出中断信号通知CPU IO操作已经完成 设备驱动程序与文件系统接口设备控制器不属于操作系统的一部分，设备还需要提供设备驱动程序，并将其安装到内核中，内核通过文件系统接口与设备驱动程序进行交互（设备也是文件，在dev目录下）","link":"/2021/04/08/os/4.io/"},{"title":"5.进程间通信","text":"进程间通信机制进程间通信有以下5种机制 管道 消息队列 共享内存+信号量 信号 信号kill -l 命令，查看所有的信号；可以通过kill命令发送信号给进程 1234567891011121314151617181920212223242526272829303132333435363738# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX# man 7 signalSignal Value Action Comment──────────────────────────────────────────────────────────────────────SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling processSIGINT 2 Term Interrupt from keyboardSIGQUIT 3 Core Quit from keyboardSIGILL 4 Core Illegal InstructionSIGABRT 6 Core Abort signal from abort(3)SIGFPE 8 Core Floating point exceptionSIGKILL 9 Term Kill signalSIGSEGV 11 Core Invalid memory referenceSIGPIPE 13 Term Broken pipe: write to pipe with no readersSIGALRM 14 Term Timer signal from alarm(2)SIGTERM 15 Term Termination signalSIGUSR1 30,10,16 Term User-defined signal 1SIGUSR2 31,12,17 Term User-defined signal 2…… 一旦信号产生，有以下几种处理方式 执行默认操作；如Term指的就是终止进程，Core指的是终止进程后，通过 Core Dump 将当前进程的运行状态保存在文件里 捕捉信号，通过自定义的信号处理函数进行处理 忽略信号 设置信号处理函数 123456789101112131415//signaltypedef void (*sighandler_t)(int);sighandler_t signal(int signum, sighandler_t handler);//sigaction（推荐）int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);struct sigaction { __sighandler_t sa_handler; unsigned long sa_flags; __sigrestore_t sa_restorer; sigset_t sa_mask; /* mask last for extensibility */}; 可靠信号：通过队列，信号依序执行 不可靠信号：信号执行中会丢信号 管道管道分为匿名管道和命名管道两种，像bash里调用ps -ef | grep xxx的|就是匿名管道。一个进程可以将数据写入管道，领一个进程从管道中读取数据 12345//创建匿名管道，通过一个输入文件描述符和一个输出文件描述符关联起来int pipe(int fd[2])//关联两个文件描述符int dup2(int oldfd, int newfd); 一个简单的demo 123456789101112131415161718192021222324252627282930313233#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[]){ int fds[2]; if (pipe(fds) == -1) perror(&quot;pipe error&quot;); pid_t pid; pid = fork(); if (pid == -1) perror(&quot;fork error&quot;); if (pid == 0){ close(fds[0]); char msg[] = &quot;hello world&quot;; write(fds[1], msg, strlen(msg) + 1); close(fds[1]); exit(0); } else { close(fds[1]); char msg[128]; read(fds[0], msg, 128); close(fds[0]); printf(&quot;message : %s\\n&quot;, msg); return 0; }} A|B的demo，假设shell进程fork出A、B两个子进程 123456789101112131415161718192021222324252627282930313233#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[]){ int fds[2]; if (pipe(fds) == -1) perror(&quot;pipe error&quot;); pid_t pid; pid = fork(); if (pid == -1) perror(&quot;fork error&quot;); if (pid == 0){ dup2(fds[1], STDOUT_FILENO); close(fds[1]); close(fds[0]); execlp(&quot;ps&quot;, &quot;ps&quot;, &quot;-ef&quot;, NULL); } else { dup2(fds[0], STDIN_FILENO); close(fds[0]); close(fds[1]); execlp(&quot;grep&quot;, &quot;grep&quot;, &quot;systemd&quot;, NULL); } return 0;} 通过mkfifo创建命名管道 123456# mkfifo hello# echo &quot;hello world&quot; &gt; hello# cat &lt; hello hello world 消息队列消息队列关键的三个库函数 msgget：创建消息队列 msgsnd：发送消息 msgrcv：接受消息 发送方demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;#include &lt;getopt.h&gt;#include &lt;string.h&gt;struct msg_buffer { long mtype; char mtext[1024];};int main(int argc, char *argv[]) { int next_option; const char* const short_options = &quot;i:t:m:&quot;; const struct option long_options[] = { { &quot;id&quot;, 1, NULL, 'i'}, { &quot;type&quot;, 1, NULL, 't'}, { &quot;message&quot;, 1, NULL, 'm'}, { NULL, 0, NULL, 0 } }; int messagequeueid = -1; struct msg_buffer buffer; buffer.mtype = -1; int len = -1; char * message = NULL; do { next_option = getopt_long (argc, argv, short_options, long_options, NULL); switch (next_option) { case 'i': messagequeueid = atoi(optarg); break; case 't': buffer.mtype = atol(optarg); break; case 'm': message = optarg; len = strlen(message) + 1; if (len &gt; 1024) { perror(&quot;message too long.&quot;); exit(1); } memcpy(buffer.mtext, message, len); break; default: break; } }while(next_option != -1); if(messagequeueid != -1 &amp;&amp; buffer.mtype != -1 &amp;&amp; len != -1 &amp;&amp; message != NULL){ if(msgsnd(messagequeueid, &amp;buffer, len, IPC_NOWAIT) == -1){ perror(&quot;fail to send message.&quot;); exit(1); } } else { perror(&quot;arguments error&quot;); } return 0;} 接收方demo 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;#include &lt;getopt.h&gt;#include &lt;string.h&gt;struct msg_buffer { long mtype; char mtext[1024];};int main(int argc, char *argv[]) { int next_option; const char* const short_options = &quot;i:t:&quot;; const struct option long_options[] = { { &quot;id&quot;, 1, NULL, 'i'}, { &quot;type&quot;, 1, NULL, 't'}, { NULL, 0, NULL, 0 } }; int messagequeueid = -1; struct msg_buffer buffer; long type = -1; do { next_option = getopt_long (argc, argv, short_options, long_options, NULL); switch (next_option) { case 'i': messagequeueid = atoi(optarg); break; case 't': type = atol(optarg); break; default: break; } }while(next_option != -1); if(messagequeueid != -1 &amp;&amp; type != -1){ if(msgrcv(messagequeueid, &amp;buffer, 1024, type, IPC_NOWAIT) == -1){ perror(&quot;fail to recv message.&quot;); exit(1); } printf(&quot;received message type : %d, text: %s.&quot;, buffer.mtype, buffer.mtext); } else { perror(&quot;arguments error&quot;); } return 0;} 共享内存共享内存相关操作 1234567891011//创建共享内存int shmget(key_t key, size_t size, int flag);//将共享内存映射到进程的内存空间void *shmat(int shm_id, const void *addr, int flag);//取消共享内存的关联int shmdt(void *addr); //删除共享内存int shmctl(int shm_id, int cmd, struct shmid_ds *buf); 信号量相关操作，常说的PV操作，P指的是申请资源操作，V指的是归还资源操作 1234567891011121314151617181920212223//创建信号量int semget(key_t key, int num_sems, int sem_flags);//初始化信号量资源数量int semctl(int semid, int semnum, int cmd, union semun args);union semun{ int val; struct semid_ds *buf; unsigned short int *array; struct seminfo *__buf;};//信号量PV操作int semop(int semid, struct sembuf semoparray[], size_t numops);struct sembuf { short sem_num; // 信号量组中对应的序号，0～sem_nums-1 short sem_op; // 信号量值在一次操作中的改变量 short sem_flg; // IPC_NOWAIT, SEM_UNDO} demo：share.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/sem.h&gt;#include &lt;string.h&gt;#define MAX_NUM 128struct shm_data { int data[MAX_NUM]; int datalength;};union semun { int val; struct semid_ds *buf; unsigned short int *array; struct seminfo *__buf; }; int get_shmid(){ int shmid; key_t key; if((key = ftok(&quot;/root/sharememory/sharememorykey&quot;, 1024)) &lt; 0){ perror(&quot;ftok error&quot;); return -1; } shmid = shmget(key, sizeof(struct shm_data), IPC_CREAT|0777); return shmid;}int get_semaphoreid(){ int semid; key_t key; if((key = ftok(&quot;/root/sharememory/semaphorekey&quot;, 1024)) &lt; 0){ perror(&quot;ftok error&quot;); return -1; } semid = semget(key, 1, IPC_CREAT|0777); return semid;}int semaphore_init (int semid) { union semun argument; unsigned short values[1]; values[0] = 1; argument.array = values; return semctl (semid, 0, SETALL, argument); }int semaphore_p (int semid) { struct sembuf operations[1]; operations[0].sem_num = 0; operations[0].sem_op = -1; operations[0].sem_flg = SEM_UNDO; return semop (semid, operations, 1); }int semaphore_v (int semid) { struct sembuf operations[1]; operations[0].sem_num = 0; operations[0].sem_op = 1; operations[0].sem_flg = SEM_UNDO; return semop (semid, operations, 1); } 生产者 1234567891011121314151617181920212223242526272829303132333435363738#include &quot;share.h&quot;int main() { void *shm = NULL; struct shm_data *shared = NULL; int shmid = get_shmid(); int semid = get_semaphoreid(); int i; shm = shmat(shmid, (void*)0, 0); if(shm == (void*)-1){ exit(0); } shared = (struct shm_data*)shm; memset(shared, 0, sizeof(struct shm_data)); semaphore_init(semid); while(1){ semaphore_p(semid); if(shared-&gt;datalength &gt; 0){ semaphore_v(semid); sleep(1); } else { printf(&quot;how many integers to caculate : &quot;); scanf(&quot;%d&quot;,&amp;shared-&gt;datalength); if(shared-&gt;datalength &gt; MAX_NUM){ perror(&quot;too many integers.&quot;); shared-&gt;datalength = 0; semaphore_v(semid); exit(1); } for(i=0;i&lt;shared-&gt;datalength;i++){ printf(&quot;Input the %d integer : &quot;, i); scanf(&quot;%d&quot;,&amp;shared-&gt;data[i]); } semaphore_v(semid); } }} 消费者 12345678910111213141516171819202122232425262728293031323334#include &quot;share.h&quot;int main() { void *shm = NULL; struct shm_data *shared = NULL; int shmid = get_shmid(); int semid = get_semaphoreid(); int i; shm = shmat(shmid, (void*)0, 0); if(shm == (void*)-1){ exit(0); } shared = (struct shm_data*)shm; while(1){ semaphore_p(semid); if(shared-&gt;datalength &gt; 0){ int sum = 0; for(i=0;i&lt;shared-&gt;datalength-1;i++){ printf(&quot;%d+&quot;,shared-&gt;data[i]); sum += shared-&gt;data[i]; } printf(&quot;%d&quot;,shared-&gt;data[shared-&gt;datalength-1]); sum += shared-&gt;data[shared-&gt;datalength-1]; printf(&quot;=%d\\n&quot;,sum); memset(shared, 0, sizeof(struct shm_data)); semaphore_v(semid); } else { semaphore_v(semid); printf(&quot;no tasks, waiting.\\n&quot;); sleep(1); } }}","link":"/2021/04/11/os/5.ipc/"},{"title":"1.分布式事务解决方案","text":"2PC2PC的解决方案非常简单，引入一个事务管理器，事务管理器要求每个涉及到事务的数据库预提交(precommit)操作，如果都就绪了，事务协调器要求每个数据库提交数据，否则回滚数据 TCCTCC将分布式事务转换成一种业务逻辑，通过补偿机制确保数据的一致性，整个流程如下： Try阶段：尝试执行，完成所有业务检查，从业务层面锁定资源 Confirm阶段：使用Try阶段锁定的业务资源，完成事务操作，且Confirm操作需要满足幂等性，失败后进行补偿，从而确保提交后数据的一致性 Cancel阶段：释放Try阶段预留的业务资源，Cancel操作也需要支持幂等，这样可以确保回退后数据的一致性 以这个库为例，https://github.com/liuyangming/ByteTCC/ ，实现买水付款的业务逻辑，这个业务逻辑涉及水的库存和钱包余额，Try阶段需要检查库存是否足够，钱包余额是否充足，尝试锁定库存里的水和钱包里的付款金额，Confirm阶段减去库存和钱包金额即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 尝试锁定账号金额@Service(&quot;accountService&quot;)@Compensable( interfaceClass = IAccountService.class , confirmableKey = &quot;accountServiceConfirm&quot;, cancellableKey = &quot;accountServiceCancel&quot;)public class AccountServiceImpl implements IAccountService { @Resource(name = &quot;jdbcTemplate&quot;) private JdbcTemplate jdbcTemplate; @Transactional public void increaseAmount(String accountId, double amount) throws ServiceException { this.jdbcTemplate.update(&quot;update tb_account set frozen = frozen + ? where acct_id = ?&quot;, amount, acctId); }}// 提交扣款@Service(&quot;accountServiceConfirm&quot;)public class AccountServiceConfirm implements IAccountService { @Resource(name = &quot;jdbcTemplate&quot;) private JdbcTemplate jdbcTemplate; @Transactional public void increaseAmount(String accountId, double amount) throws ServiceException { this.jdbcTemplate.update(&quot;update tb_account set amount = amount - ?, frozen = frozen - ? where acct_id = ?&quot;, amount, amount, acctId); }}// 交易失败，解锁账号内的金额锁定@Service(&quot;accountServiceCancel&quot;)public class AccountServiceCancel implements IAccountService { @Resource(name = &quot;jdbcTemplate&quot;) private JdbcTemplate jdbcTemplate; @Transactional public void increaseAmount(String accountId, double amount) throws ServiceException { this.jdbcTemplate.update(&quot;update tb_account set frozen = frozen - ? where acct_id = ?&quot;, amount, acctId); }} 本地消息表这是一种ebay提出的解决方案，本质上是将一个大事务拆分成多个小事务。上游服务首先锁定写业务数据，然后将一条消息写入MQ，并将消息id落表，写业务数据和消息id落表在同一个事务里。下游消费消息后，写完业务数据后，通过消息id回调上游服务。只要整个过程支持幂等重试，就可以保证数据的一致性 MQ事务MQ事务其实是对本地消息表的一个封装，将本地消息表移动到了MQ内部。比如RocketMQ就支持事务功能 生产端 提交Prepared消息，拿到消息id 执行本地事务 通过消息id提交消息，如果提交失败，这个MQ事务的状态不确定，RocketMQ会回查这个事务的状态 下游消费端通过RocketMQ的幂等重试机制确保数据一致性","link":"/2021/04/19/distributed_system/1.distributed_transaction/"}],"tags":[{"name":"一、算法与数据结构","slug":"一、算法与数据结构","link":"/tags/%E4%B8%80%E3%80%81%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"三、深入理解Java虚拟机","slug":"三、深入理解Java虚拟机","link":"/tags/%E4%B8%89%E3%80%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"二、Leetcode刷题","slug":"二、Leetcode刷题","link":"/tags/%E4%BA%8C%E3%80%81Leetcode%E5%88%B7%E9%A2%98/"},{"name":"六、Netty","slug":"六、Netty","link":"/tags/%E5%85%AD%E3%80%81Netty/"},{"name":"九、Mysql","slug":"九、Mysql","link":"/tags/%E4%B9%9D%E3%80%81Mysql/"},{"name":"六、计算机网络","slug":"六、计算机网络","link":"/tags/%E5%85%AD%E3%80%81%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"五、操作系统","slug":"五、操作系统","link":"/tags/%E4%BA%94%E3%80%81%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"十、分布式系统解决方案","slug":"十、分布式系统解决方案","link":"/tags/%E5%8D%81%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"}],"categories":[{"name":"一、算法与数据结构","slug":"一、算法与数据结构","link":"/categories/%E4%B8%80%E3%80%81%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"三、深入理解Java虚拟机","slug":"三、深入理解Java虚拟机","link":"/categories/%E4%B8%89%E3%80%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"二、Leetcode刷题","slug":"二、Leetcode刷题","link":"/categories/%E4%BA%8C%E3%80%81Leetcode%E5%88%B7%E9%A2%98/"},{"name":"六、Netty","slug":"六、Netty","link":"/categories/%E5%85%AD%E3%80%81Netty/"},{"name":"九、Mysql","slug":"九、Mysql","link":"/categories/%E4%B9%9D%E3%80%81Mysql/"},{"name":"六、计算机网络","slug":"六、计算机网络","link":"/categories/%E5%85%AD%E3%80%81%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"五、操作系统","slug":"五、操作系统","link":"/categories/%E4%BA%94%E3%80%81%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"十、分布式系统","slug":"十、分布式系统","link":"/categories/%E5%8D%81%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}]}